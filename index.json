[{"authors":["admin"],"categories":null,"content":"Giuseppe Manco is Director of Research at the Institute of High Performance Computing and Networks of the National Research Council of Italy. His research interests include User Profiling and Behavioral Modeling, Social Network Analysis, Information Propagation and Diffusion, Recommender Systems, Machine Learning for Cybersecurity.\nExpert on data science, data analytics and enabling technologies for data analytics. Interested in new frontiers of Computer Science and Technology aimed at analyzing Complex Big Data. Co-founder of Open Knowledge Technologies (OKT), a spin-off company of University of Calabria aimed at bringing innovation from academia to industry on the specific topics of Artificial Intelligence and Cybersecurity.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://gmanco.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Giuseppe Manco is Director of Research at the Institute of High Performance Computing and Networks of the National Research Council of Italy. His research interests include User Profiling and Behavioral Modeling, Social Network Analysis, Information Propagation and Diffusion, Recommender Systems, Machine Learning for Cybersecurity.\nExpert on data science, data analytics and enabling technologies for data analytics. Interested in new frontiers of Computer Science and Technology aimed at analyzing Complex Big Data.","tags":null,"title":"Giuseppe Manco","type":"authors"},{"authors":null,"categories":null,"content":" Annunci  [01/03/2021] Questo è il sito web dell\u0026rsquo;edizione 2020-2021 del corso. L\u0026rsquo;edizione precedente è disponibile al sequente link. [03/03/2021] Si avvisano gli studenti che il corso di Analisi di Immagini e Video – Corso di Laurea Magistrale in Ingegneria Informatica verrà inizialmente erogato in modalità streaming, utilizzando l’applicativo TEAMS, a partire dal giorno 02/03/2019, alle ore 11:30. La richiesta di iscrizione al corso può essere effettuata cliccando sul seguente link. Gli studenti già pratici dell’utilizzo di TEAMS e che abbiano già scaricato l’APP, possono iscriversi direttamente al corso (senza approvazione del docente) utilizzando il codice: czo3mqk  Breve descrizione del corso Il corso è finalizzato ad acquisire e sperimentare le tecniche di base per l’analisi di immagini e video. Verranno illustrati i concetti fondamentali per l’analisi delle immagini e verranno illustrate le principali tecniche di object detection, object tracking e action detection. Durante il corso saranno presentati modelli di reti neurali CNN e RNN, tecniche di transfer learning, Residual and Attention network ed una introduzione ai modelli generativi e alle Adversarial networks. Gli esempi applicativi faranno uso del linguaggio Python e dei framework di Deep Learning Pytorch/Tensorflow.\nCompetenze specifiche:\n comprensione dei concetti legati all’image e al video processing conoscenza degli aspetti caratterizzanti di machine learning e deep learning comprensione delle principali tecniche per l’analisi di immagini e video abilità di utilizzare algoritmi di image analysis per la risoluzione di problemi specifici  Docenti  Giuseppe Manco. Ricevimento: mercoledì’ 14:30-16:30. Francesco Pisani. Rivevimento lunedì 15-17.  Programma  Introduzione alla computer vision  Concetti fondamentali su Image processing e analysis: Image Basics, Python per Image Processing, Manipolazione di immagini. Trasformazioni: Normalizzazione, filtri, Edge detection, morfologia, thresholding e segmentazione.  Classificazione di immagini e video  Introduzione alla classificazione: applicazioni; approcci classici; scikit-Learn per la classificazione; limitazioni. Deep Learning: Review su Neural Networks per l\u0026rsquo;analisi di immagini e video. Convolutional Neural Networks. Reti ricorrenti. Gestione dell\u0026rsquo;overfitting. Concetti avanzati. Principali architetture di rete e loro caratteristiche: VGG, AlexNet, Inception and Residual Networks, Attention Networks. Transfer Learning.  Concetti avanzati  Object Detection: Sliding windows, boundary boxes e anchors. Region Proposal Networks. Yolo e Darknet. Applicazioni. Object tracking e action recognition. Optical flow; Single/multiple objects tracking; Action classification and localization. Image segmentation e synthesis. UNet. Neural style transfer. Modelli Generativi: Probabilistic Modeling, Autoencoders. Generative Adversarial Networks. Applicazioni: Colorization, Reconstruction, Super-Resolution, Synthesis, Text-to-image. Adversarial Machine Learning. Principali attacchi e contromisure. Adversarial-free deep networks.   Materiale didattico  Lucidi delle lezioni Notebooks e lucidi delle esercitazioni Libri di consultazione:  E.R. Davies, Computer Vision: Principles, Algorithms, Applications, Learning. Fifth edition. Elsevier/Academic Press, 2018 [Davies18] Jan Erik Solem, Programming Computer Vision with Python. O\u0026rsquo;Reilly Media, 2012. [Solem12] Mohamed Elgendy, Deep Learning for Vision Systems. Manning, 2020. [Elg20] Rafael C. Gonzalez, Richard E. Woods, Digital image processing. 4th edition. Pearson, 2018. [Gon18] Richard Szeliski, Computer Vision: Algorithms and Applications. Springer, 2011. [Sze11] Jason M.Kinser, Image operators: image processing in Python. CRC Press, 2019. [Kin19]   Sillabo delle lezioni    Lezione Argomenti Materiale didattico Data     1 Introduzione al corso Slides 02/03/2021   2 Python and image processing Slides, notebook 04/03/2021   3 Concetti fondamentali su image processing e analysis Slides, notebook 09/03/2021    ","date":1614556800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1614556800,"objectID":"63ae979fd283aabb2a9d1b1c9e94f224","permalink":"https://gmanco.github.io/courses/computervision/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/courses/computervision/","section":"courses","summary":"Il corso mira a fornire solide basi in merito all’analisi di immagini e video e fornire una conoscenza delle principali tecniche di deep learning per il riconoscimento di oggetti e l’individuazione di sequenze rilevanti in un video.","tags":null,"title":"Panoramica","type":"docs"},{"authors":null,"categories":null,"content":" Annunci  [31/07/2020] Rilasciate le specifiche progetto per esame del 03/09/2020. La consegna degli elaborati deve avvenire il 01/09/2020. [01/07/2020] Rilasciate le specifiche progetto per esame del 31/07/2020. La consegna degli elaborati deve avvenire il 29/07/2020. [09/06/2020] Rilasciate le specifiche progetto per esame del 01/07/2020. La consegna degli elaborati deve avvenire il 28/06/2020. [08/06/2020] E disponibile la valutazione del secondo esonero, nalla rispettiva pagina. [07/05/2020] E disponibile la valutazione del primo esonero, nalla rispettiva pagina. [28/04/2020] E disponibile la lista degli argomenti per il secondo esonero. La lista è disponibile qui. Gli studenti che selgono di effettuare l\u0026rsquo;esonero devono concordare l\u0026rsquo;opzione con il docente tramite email. La deadline per la consegna degli elaborati è il 10 maggio 2020. [02/04/2020] E disponibile la lista degli argomenti per il primo esonero. La lista è disponibile qui. Gli studenti che selgono di effettuare l\u0026rsquo;esonero devono comunicare le opzioni (3) al docente. Martedì 7 verrà comunicata l\u0026rsquo;assegnazione dei topic ai vari studenti. La deadline per la consegna degli elaborati è il 16 aprile 2020. [03/03/2020] Si avvisano gli studenti che il corso di Analisi di Immagini e Video – Corso di Laurea Magistrale in Ingegneria Informatica verrà erogato in modalità streaming, utilizzando l’applicativo TEAMS, a partire dal giorno 17/03/2019, alle ore 8:30. La richiesta di iscrizione al corso può essere effettuata cliccando sul seguente link. Gli studenti già pratici dell’utilizzo di TEAMS e che abbiano già scaricato l’APP, possono iscriversi direttamente al corso (senza approvazione del docente) utilizzando il codice: khm7h4s  Breve descrizione del corso Il corso è finalizzato ad acquisire e sperimentare le tecniche di base per l’analisi di immagini e video. Verranno illustrati i concetti fondamentali per l’analisi delle immagini e verranno illustrate le principali tecniche di object detection, object tracking e action detection. Durante il corso saranno presentati modelli di reti neurali CNN e RNN, tecniche di transfer learning, Residual and Attention network ed una introduzione ai modelli generativi e alle Adversarial networks. Gli esempi applicativi faranno uso del linguaggio Python e dei framework di Deep Learning Pytorch/Tensorflow.\nCompetenze specifiche:\n comprensione dei concetti legati all’image e al video processing conoscenza degli aspetti caratterizzanti di machine learning e deep learning comprensione delle principali tecniche per l’analisi di immagini e video abilità di utilizzare algoritmi di image analysis per la risoluzione di problemi specifici  Docenti  Giuseppe Manco. Ricevimento: mercoledì’ 14:30-16:30. Francesco Pisani. Rivevimento lunedì 15-17.  Programma  Introduzione alla computer vision  Concetti fondamentali su Image processing e analysis: Image Basics, Python per Image Processing, Manipolazione di immagini. Trasformazioni: Normalizzazione, filtri, Edge detection, morfologia, thresholding e segmentazione.  Classificazione di immagini e video  Introduzione alla classificazione: applicazioni; approcci classici; scikit-Learn per la classificazione; limitazioni. Deep Learning: Review su Neural Networks per l\u0026rsquo;analisi di immagini e video. Convolutional Neural Networks. Reti ricorrenti. R-CNN. Gestione dell\u0026rsquo;overfitting. Concetti avanzati. Principali architetture di rete e loro caratteristiche: VGG, AlexNet, Inception and Residual Networks, Attention Networks. Transfer Learning.  Concetti avanzati  Object Detection: Sliding windows, boundary boxes e anchors. Region Proposal Networks. Yolo e Darknet. Applicazioni. Object tracking e action recognition. Optical flow; Single/multiple objects tracking; Action classification and localization. Image segmentation e synthesis. UNet. Neural style transfer. Modelli Generativi: Probabilistic Modeling, Autoencoders. Generative Adversarial Networks. Applicazioni: Colorization, Reconstruction, Super-Resolution, Synthesis, Text-to-image. Adversarial Machine Learning. Principali attacchi e contromisure. Adversarial-free deep networks.   Materiale didattico  Lucidi delle lezioni Notebooks e lucidi delle esercitazioni Libri di consultazione:  E.R. Davies, Computer Vision: Principles, Algorithms, Applications, Learning. Fifth edition. Elsevier/Academic Press, 2018 [Davies18] Jan Erik Solem, Programming Computer Vision with Python. O\u0026rsquo;Reilly Media, 2012. [Solem12] Mohamed Elgendy, Deep Learning for Vision Systems. Manning, 2020. [Elg20] Rafael C. Gonzalez, Richard E. Woods, Digital image processing. 4th edition. Pearson, 2018. [Gon18] Richard Szeliski, Computer Vision: Algorithms and Applications. Springer, 2011. [Sze11] Jason M.Kinser, Image operators: image processing in Python. CRC Press, 2019. [Kin19]   Sillabo delle lezioni    Lezione Argomenti Materiale didattico Data     1 Introduzione al corso Slides 17/03/2020   2 Concetti fondamentali su Image processing e analysis Slides, notebook 19/03/2020   3 Filtri Slides, notebook 24/03/2020   4 Laboratorio 1: Image Processing in Python Slides, notebook 26/03/2020   5 Edge detection. Fourier Transform Slides, notebook 31/03/2020   6 Classificazione. Feature detection \u0026amp; Description Slides. Esonero 02/04/2020   7 Laboratorio 2: sklearn. Pytorch Slides, notebook 07/04/2020   8 Modelli non lineari. CNN Slides, notebook 16/04/2020, 21/04/2020   10 Laboratorio 3: Architetture CNN, data augmentation, transfer learning Slides, notebook 23/04/2020   11 Object Detection. Region Proposal Networks, Single-Shot Detection. Yolo. Slides, notebooks 28/04/2020, 30/04/2020   12 Laboratorio 4: Object Detection Notebook 05/05/2020   13 Segmentazione Slides, notebooks 07/05/2020, 12/05/2020, 14/05/2020   14 Action Recognition Slides, notebooks 19/05/2020   15 Modelli generativi. Variational Autoencoders Slides, notebooks 21/05/2020   16 Generative Adversarial Networks. Image translation Slides, notebooks 26/05/2020, 28/05/2020   17 Laboratorio 5: Generative Adversarial Networks Slides, notebook 04/06/2020    ","date":1582675200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1587168000,"objectID":"87c505009f96d198f18696ce7f4660d9","permalink":"https://gmanco.github.io/courses/computervision/2020/","publishdate":"2020-02-26T00:00:00Z","relpermalink":"/courses/computervision/2020/","section":"courses","summary":"Il corso mira a fornire solide basi in merito all’analisi di immagini e video e fornire una conoscenza delle principali tecniche di deep learning per il riconoscimento di oggetti e l’individuazione di sequenze rilevanti in un video.","tags":null,"title":"Analisi di Immagini e Video - A.A. 2019-2020","type":"docs"},{"authors":null,"categories":null,"content":" Introduzione al corso. Image Processing, Analysis e Computer Vision.\nSlides disponibili qui\nRiferimenti bibliografici  [Davies18], ch. 1. [Elg20], sect. 1.1-1.3. [Gon18], Ch. 1. [Sze11], Ch. 1,2.  Link utili  Introduction to Computer Vision A gentle introduction to Computer Vision A Beginner\u0026rsquo;s guide to Computer Vision Everything you wanted to know about Computer Vision The Computer Vision Foundation Three ways Computer Vision is transforming Marketing  Approfondimenti (contributi dagli studenti): Alcune applicazioni per la computer vision Amazon GO Il progetto Amazon GO consiste in un negozio in cui non è presente alcuna cassa in quanto il check-out avviene automaticamente direttamente sul proprio account Amazon. I clienti attivano l’app sul telefono e scansionano il proprio qr-code prima di entrare nel negozio, dopodiché un sistema di videocamere e sensori tracceranno gli spostamenti dei clienti, tenendo traccia dei prodotti da loro acquistati. All’uscita dal negozio si scansiona nuovamente il qr-code ed i prodotti acquistati verranno addebitati direttamente sul proprio account amazon. Riferimenti: - 1 - 2\nBlood loss monitoring Questo sistema utilizza le immagini delle spugne chirurgiche e delle taniche di aspirazione per andare a stimare la perdita di sangue tramite il processamento di tali immagini tramite algoritmi di machine learning e di computer vision. Questa applicazione viene utilizzata in alcuni ospedali durante i parti cesarei. Tali misurazioni risultano essere più accurate delle valutazioni fatte ad occhio nudo e risultano essere fondamentali per stabilire se siano necessarie trasfusioni o meno. Riferimenti: - 1 - 2\nReal-time sports tracking La computer vision viene utilizzata per aiutare quella che è l’analisi di gioco e delle strategie ed anche per andare a misurare le performance dei giocatori, questa però non è la sola applicazione utilizzata infatti quest’ultima viene utilizzata anche per studiare quella che è la visibilità dei brand presenti ad esempio sulle divise dei giocatori. Questo è quello che viene effettuato dall’azienda Gumgum. Riferimenti: - 1 - 2\nFrom image to 3D models La computer vision ha consentito la costruzione di sistemi in grado di ricostruire modelli 3d a partire dalle immagini. I dettagli di tale lavoro sono descritti nel seguente paper. Quest’ultimo mostra anche una serie di campi in cui viene impiegata tale applicazione. Link utili: - 1\nFood quality control La computer vision viene utilizzata anche per effettuare la valutazione della qualità del cibo, tale applicazione viene facilmente utilizzata nel campo industriale in quanto veloce e maggiormente oggettiva rispetto all’analisi umana. Il paper riportato riporta una carrellata di tecniche utilizzate e dell’accuratezza da esse riportate per diverse tipologie di cibo che vanno dalla verdura alla frutta a cibi più complessi come ad esempio la pizza ed i dolci. Link utili: - 1\n","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585177200,"objectID":"6f5e360b2e5e2cd53f611c3808fbb08e","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture1/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture1/","section":"courses","summary":"Introduzione al corso. Image Processing, Analysis e Computer Vision.\nSlides disponibili qui\nRiferimenti bibliografici  [Davies18], ch. 1. [Elg20], sect. 1.1-1.3. [Gon18], Ch. 1. [Sze11], Ch. 1,2.  Link utili  Introduction to Computer Vision A gentle introduction to Computer Vision A Beginner\u0026rsquo;s guide to Computer Vision Everything you wanted to know about Computer Vision The Computer Vision Foundation Three ways Computer Vision is transforming Marketing  Approfondimenti (contributi dagli studenti): Alcune applicazioni per la computer vision Amazon GO Il progetto Amazon GO consiste in un negozio in cui non è presente alcuna cassa in quanto il check-out avviene automaticamente direttamente sul proprio account Amazon.","tags":null,"title":"Introduzione al corso","type":"docs"},{"authors":null,"categories":null,"content":" Introduzione al corso. Image Processing, Analysis e Computer Vision.\nSlides disponibili qui (Con video associato su Microsoft Stream)\nRiferimenti bibliografici  [Davies18], ch. 1. [Elg20], sect. 1.1-1.3. [Gon18], Ch. 1. [Sze11], Ch. 1,2.  Link utili  Introduction to Computer Vision A gentle introduction to Computer Vision A Beginner\u0026rsquo;s guide to Computer Vision Everything you wanted to know about Computer Vision The Computer Vision Foundation Three ways Computer Vision is transforming Marketing https://www.sciencedirect.com/science/article/pii/S0168169902001011)  Approfondimento: Ambiti applicativi (con il contributo degli studenti) Rilevamento attenzione del conducente1 Gli algoritmi di apprendimento automatico e deep learning, a cui sono stati forniti migliaia di dati di volti attenti e disattenti, possono rilevare differenze tra occhi concentrati e stanchi, nonché indizi che rivelano una guida distratta. L\u0026rsquo;intelligenza artificiale in questo contesto è importante perché permette di proteggere sia il conducente che le altre entità limitrofe. Questo aspetto della computer vision inoltre può essere usato per rilevare eventuali conducenti che guidano in stato di ebbrezza.\nRiferimenti\nConteggio persone e distanza COVID1 Purtroppo il 2020 ha visto il diffondersi di un virus che ha investito la popolazione mondiale. Ogni persona è stata costretta a dover rispettare delle regole per cercare di contrastare il diffondersi della pandemia ed anche in questo spiacevole contesto, la computer vision ha assunto un ruolo peculiare. La tecnologia di interesse è stata sfruttata per esempio per rilevare eventuali assembramenti, per il conteggio delle persone, per l’individuazione di soggetti privi di mascherina. Uno dei progetti di ricerca anti-Covid a cui lavora Unimore ha l’obiettivo di realizzare un sistema che analizza i video, localizza le persone nello spazio 3D, riconosce le mascherine e calcola distanze. Usa l’intelligenza artificiale per il distanziamento sociale in spazi aperti e può essere di grande aiuto alle istituzioni per il calcolo in tempo reale degli assembramenti, così da ridurre il rischio di contagio nei luoghi pubblici.\nRiferimenti 1 e 2\nDrishti, intelligenza artificiale al servizio degli ipovedenti1 Drishti, dal sanscrito “sguardo” è una tecnologia che attraverso un paio di occhiali, similissimi a comuni occhiali, e grazie alla tecnologia racchiusa in essi permette alle persone ipovedenti di guardare ciò che li circonda. Questa tecnologia permette di avere un senso in più: un senso tecnologico, fatto di bit e intelligenza artificiale, che attraverso una micro-camera nascosta nella montatura degli smart glasses e ad un software sviluppato dagli “Accenture Labs” consente anche a chi è ipovedente o cieco di gettare uno sguardo sul mondo che lo circonda.\nRiferimenti 1 e 2\nManifacturing1 Nell’ambito della produzione, la visione artificiale abbinata ai sensori può essere sfruttata per gestire e monitorare lo stato delle apparecchiature e degli strumenti. Oggi, la tecnologia viene utilizzata per controllare importanti impianti o attrezzature al loro interno. I guasti e i problemi dell\u0026rsquo;infrastruttura possono essere prevenuti con l\u0026rsquo;aiuto di una visione artificiale realizzata per stimare lo stato e l\u0026rsquo;efficienza delle macchine. Molte aziende stanno usando questa tipologia di manutenzione per mantenere i propri strumenti in buone condizioni. Ad esempio, il software ZDT realizzato da FANUC è un software di manutenzione preventiva progettato per raccogliere immagini dalla telecamera collegata ai robot. Quindi questi dati vengono elaborati per fornire la diagnosi dei problemi e rilevare eventuali problemi potenziali.\nRiferimenti\nVideo sorveglianza e Customer profiling1 La Computer Vision viene applicata alla videosorveglianza automatica per una serie di obiettivi che includono la gestione delle folle e la misurazione dell’efficacia del marketing. Grazie al Deep Learning possono essere sviluppate anche soluzioni per il conteggio delle persone e Stazioni ferroviarie, aeroporti, parcheggi, centri commerciali, stadi: in tutti questi luoghi, i sistemi di videosorveglianza possono diventare più veloci e affidabili se sfruttano le potenzialità della smart safety integrata con l’intelligenza artificiale.\nRiferimenti\nVISION-2 (startup BInoocle)2 “VISION-2 è un sistema avanzato di Intelligenza Artificiale immediatamente installabile, con nessuna necessità di assistenza, che opera attraverso qualsiasi webcam o telecamera in tempo reale (diretta) per svolgere diverse funzioni ed aiutare a mantenere comportamenti sicuri”. Il sistema è stato messo a punto per incentivare comportamenti sicuri durante l’emergenza COVID, in particolare, durante la “fase 2” dell’epidemia.\nEsistono tre applicazioni diverse di Vision-2 pensate per il monitoraggio di situazioni differenti:\n Pro Person: mantenere un numero sicuro di persone per evitare gli assembramenti. Pro Person è un sistema di monitoraggio avanzato che rileva il numero e lo spostamento delle persone presenti in un luogo, inviando un segnale quando queste sono in numero superiore a quello deciso o consigliato. Aiuta quindi a tenere sempre un numero ragionevole di persone in un ambiente ed evita gli assembramenti. Face Mask: rilevare la presenza delle mascherine protettive. Face Mask è un sistema di monitoraggio avanzato che permette di rilevare la presenza delle mascherine protettive attraverso una webcam, fornendo in tempo reale segnali d’avvertimento nel caso di mancanza di protezione sui volti. Concierge: il tuo portiere di fiducia che ti aiuta a gestire gli accessi e la ila in modo sicuro. Concierge permette di gestire la fila ed il flusso in entrata in modo ordinato e preciso, rilevando il momento opportuno in cui far entrare nuovi clienti. È facilmente configurabile sul numero di persone massimo desiderate all’interno. Il cliente saprà quindi quando deve aspettare o quando potrà accedere e verrà accolto da un segnale discreto e ben visibile.  Riferimenti\nSportLogiq2 Sportlogiq è nna delle prime aziende che ha iniziato a scavare più a fondo nell\u0026rsquo;analisi abilitata dall\u0026rsquo;intelligenza artificiale. Sportlogiq aiuta le squadre di hockey, calcio e football a prendere decisioni più intelligenti utilizzando informazioni più approfondite.\nL\u0026rsquo;azienda utilizza telecamere abilitate alla visione artificiale che analizzano specifici eventi di gioco e sfumature come i movimenti dei giocatori, le traiettorie della palla, i tiri e i passaggi. Quindi questi dati vengono convertiti in rapporti significativi per allenatori, commentatori, scout, analisti e persino società di scommesse sportive delle squadre.\nSportLogic è nata con l’ obiettivo quello di portare un’intelligenza artificiale all’avanguardia nel mondo dello sport. Il team di analisti di dati di Sportlogiq elabora i dati grezzi ottenuti dai feed trasmessi e li modella in informazioni utilizzabili su misura per l\u0026rsquo;esperienza dello sport.\n· Ingressi: gli esperti di Computer Vision forniscono a Sportlogiq la tecnologia per raccogliere i dati di tracciamento che configurano il rilevamento degli eventi. Il rilevamento degli eventi, parte del processo di apprendimento automatico, consente ai team di assemblare il più grande database nello sport\n· Stima della posa: viene usata la stima della posa per comprendere la posizione e il movimento dei giocatori sul ghiaccio, sul campo o sul campo. Questa tecnologia consente un esame più forense delle prestazioni di un giocatore e una comprensione più profonda di ciò che sta accadendo nel gioco.\n· Uscite: Attraverso l\u0026rsquo;apprendimento automatico, la visione artificiale e il lavoro dei nostri analisti di dati, Sportlogiq può produrre modelli che forniscono ai team metriche rivoluzionarie come: Obiettivi previsti (hockey), tempo automatizzato sul ghiaccio (Hockey), metriche fisiche (calcio), metriche contestuali (calcio), dati di monitoraggio (calcio)\nL\u0026rsquo;accesso a queste metriche basate sull\u0026rsquo;intelligenza artificiale consente ai team di scoprire tendenze all\u0026rsquo;interno della propria squadra e dei loro avversari che danno loro un vantaggio competitivo\nRiferimenti 1 e 2\nGoogle Lens2 Google Lens è una applicazione mobile per il riconoscimento delle immagini sviluppata da Google. È stata progettata per portare informazioni pertinenti ad oggetti utilizzando l’analisi visiva. Inizialmente veniva fornita come app a parte, in seguito è stata integrata alla fotocamera Android.\nGoogle Lens riconosce gli oggetti e suggerisce le azioni appropriate. Le diverse funzionalità sono:\n Scansione e traduzione del testo: per tradurre testo in tempo reale, cercare parole, aggiungere aventi al calendario. Acquisti: per cercare i negozi che vendono gli oggetti inquadrati Menu: per cercare del cibo da ordinare al ristorante direttamente dal menù Visita: esplorare luoghi visini, orari di apertura, fatti storici. Identifica: per scoprire il tipo di pianta o la razza del cane inquadrato  Riferimenti\nCOVID-193 L’ultima minaccia per la salute globale è l’epidemia in corso di COVID-19. La Computer Vision ha avuto recentemente successo nella risoluzione di vari problemi riguardanti l’assistenza sanitaria e ha il potenziale per contribuire alla sfida contro il COVID-19. In particolare, le tecniche di visione artificiale possono essere adoperate in tre aree di ricerca differenti riassunte nello schema sotto riportato.\nRiferimenti\nControllo della qualità nelle industrie3 I sistemi di Computer Vision possono essere impiegati con successo nel campo dell’automazione industriale per il controllo qualità. Infatti, le tecnologie che adoperano la Computer Vision consentono di rilevare difetti, migliorare la qualità dei prodotti e ridurre i costi di produzione.\nRiferimenti 1, 2, 3\nAssistenza per persone ipovedenti3 Per le persone ipovedenti o affette da cecità anche attività giornaliere molto semplici possono essere difficili da affrontare. Mediante l’utilizzo della visione artificiale tali problematiche possono essere affrontate grazie al Visual Question Answering. Una persona ipovedente può in questo modo scattare una foto, fare delle domande a questa inerenti e ricevere in modo rapido una risposta in linguaggio parlato che la possa guidare nelle azioni da svolgere.\nRiferimenti\nAgricoltura3 Anche nel settore agricolo vengono ormai utilizzate tecnologie volte a migliorare le attività svolte dagli essere umani. Ne vengono adoperate di diverse al fine di aiutare gli agricoltori ad adottare metodi di crescita più efficienti , aumentare i raccolti e i profitti aiutando gli stessi agricoltori a prendere decisioni in merito ai possibili trattamenti. La maggior parte di queste, infatti, catturano le immagini dei campi per evidenziare eventualmente la presenza di infestazioni da parassiti o altri fattori che potrebbero intaccare il benessere delle colture e del bestiame.\nRiferimenti 1, 2, 3\nAmbito sanitario3 In questo ambito la Computer Vision aiuta gli operatori sanitari a classificare con precisione condizioni o malattie riducendo o eliminando diagnosi imprecise e trattamenti non corretti. Un ruolo che assume sempre più significato è quello relativo alla diagnosi precoce del cancro. Recenti studi hanno infatti portato alla generazione di tecnologie in grado di classificare, ad esempio, il cancro della pelle con un tasso di accuratezza pari a quello dei medici o ancora a diagnosi più precise ed efficienti in merito alla segmentazione dei tumori cerebrali o alla riduzione della complessità dell’esame istologico, necessario per studiare le manifestazioni della malattia.\nRiferimenti\nTrasferimento del contenuto di un’immagine in un’altra (O unione di immagini)4 Riferimenti\nRiconoscimento automatico delle espressioni facciali4 Riferimenti\nReal-time Lane Detection4 Riferimenti\nRiconoscimento automatico di colori4 Riferimenti\nContatore di persone4 Riferimenti\n Giulia Natale ^ Silvia Plutino ^ Gaia Musacchio ^ Tommaso Ruga ^   ","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585177200,"objectID":"3d7f16d70e17b38150e3809885d99456","permalink":"https://gmanco.github.io/courses/computervision/lecture1/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/courses/computervision/lecture1/","section":"courses","summary":"Introduzione al corso. Image Processing, Analysis e Computer Vision.\nSlides disponibili qui (Con video associato su Microsoft Stream)\nRiferimenti bibliografici  [Davies18], ch. 1. [Elg20], sect. 1.1-1.3. [Gon18], Ch. 1. [Sze11], Ch. 1,2.  Link utili  Introduction to Computer Vision A gentle introduction to Computer Vision A Beginner\u0026rsquo;s guide to Computer Vision Everything you wanted to know about Computer Vision The Computer Vision Foundation Three ways Computer Vision is transforming Marketing https://www.","tags":null,"title":"Introduzione al corso","type":"docs"},{"authors":null,"categories":null,"content":" Python \u0026amp; image processing.\nPrincipali argomenti trattati:\n Color models Introduzione ai Jupyter notebooks Caricamento di immagini con PIL  Slides disponibili qui e qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 5. [Gon18], Ch. 3. [Solem12], Ch. 1. [Sze11], sect. 4.2. [Kin19], Ch. 13.  Link utili  PIL tutorial Scikit Image Tutorial Color models jupyterlab.readthedocs.io  ","date":1614898800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614898800,"objectID":"71ad970917002acc6c2d6322279e5769","permalink":"https://gmanco.github.io/courses/computervision/lecture_lab1/","publishdate":"2021-03-05T00:00:00+01:00","relpermalink":"/courses/computervision/lecture_lab1/","section":"courses","summary":" Python \u0026amp; image processing.\nPrincipali argomenti trattati:\n Color models Introduzione ai Jupyter notebooks Caricamento di immagini con PIL  Slides disponibili qui e qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 5. [Gon18], Ch. 3. [Solem12], Ch. 1. [Sze11], sect. 4.2. [Kin19], Ch. 13.  Link utili  PIL tutorial Scikit Image Tutorial Color models jupyterlab.readthedocs.io  ","tags":null,"title":"Python and image processing","type":"docs"},{"authors":null,"categories":null,"content":" Concetti fondamentali su Image processing e analysis: Image Basics, Manipolazione di immagini. Introduzione alle librerie Python per Image Processing.\nSlides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 2. [Elg20], sect. 1.4-1.5. [Gon18], Ch. 2-3. [Solem12], Ch. 1. [Sze11], sect. 3.1, 3.6. [Kin19], Ch.1-6.  Link utili  Stanford cs231n Python tutorial Stanford cs231n Jupyter tutorial Anaconda, la piattaforma di riferimento per installare Python e Jupyter Piattaforma azure di Microsoft per l\u0026rsquo;esecuzione di notebooks Google Colab The missing semester, un mini-corso del MIT sui tool di base che tutti i data scientist dovrebbero conoscere  ","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585177200,"objectID":"9af8bfa797533487dad2c3ed3bf67dd6","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture2/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture2/","section":"courses","summary":" Concetti fondamentali su Image processing e analysis: Image Basics, Manipolazione di immagini. Introduzione alle librerie Python per Image Processing.\nSlides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 2. [Elg20], sect. 1.4-1.5. [Gon18], Ch. 2-3. [Solem12], Ch. 1. [Sze11], sect. 3.1, 3.6. [Kin19], Ch.1-6.  Link utili  Stanford cs231n Python tutorial Stanford cs231n Jupyter tutorial Anaconda, la piattaforma di riferimento per installare Python e Jupyter Piattaforma azure di Microsoft per l\u0026rsquo;esecuzione di notebooks Google Colab The missing semester, un mini-corso del MIT sui tool di base che tutti i data scientist dovrebbero conoscere  ","tags":null,"title":"Concetti fondamentali su Image processing e analysis","type":"docs"},{"authors":null,"categories":null,"content":" Concetti fondamentali su Image processing e analysis: Image Basics, Manipolazione di immagini. Introduzione alle librerie Python per Image Processing.\nSlides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 2. [Elg20], sect. 1.4-1.5. [Gon18], Ch. 2-3. [Solem12], Ch. 1. [Sze11], sect. 3.1, 3.6. [Kin19], Ch.1-6.  Link utili  Stanford cs231n Python tutorial Stanford cs231n Jupyter tutorial Anaconda, la piattaforma di riferimento per installare Python e Jupyter Piattaforma azure di Microsoft per l\u0026rsquo;esecuzione di notebooks Google Colab The missing semester, un mini-corso del MIT sui tool di base che tutti i data scientist dovrebbero conoscere  ","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585177200,"objectID":"370182fe2b01a1596cfa2150d45b1ec3","permalink":"https://gmanco.github.io/courses/computervision/lecture2/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/courses/computervision/lecture2/","section":"courses","summary":" Concetti fondamentali su Image processing e analysis: Image Basics, Manipolazione di immagini. Introduzione alle librerie Python per Image Processing.\nSlides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 2. [Elg20], sect. 1.4-1.5. [Gon18], Ch. 2-3. [Solem12], Ch. 1. [Sze11], sect. 3.1, 3.6. [Kin19], Ch.1-6.  Link utili  Stanford cs231n Python tutorial Stanford cs231n Jupyter tutorial Anaconda, la piattaforma di riferimento per installare Python e Jupyter Piattaforma azure di Microsoft per l\u0026rsquo;esecuzione di notebooks Google Colab The missing semester, un mini-corso del MIT sui tool di base che tutti i data scientist dovrebbero conoscere  ","tags":null,"title":"Concetti fondamentali su Image processing e analysis","type":"docs"},{"authors":null,"categories":null,"content":" Manipolazione spaziale. Filtri. Convoluzione.\nSlides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], Ch. 3. [Gon18], Ch. 3. [Solem12], Ch. 1. [Sze11], sect. 3.2, 3.3. [Kin19], Ch. 2, 10-12.  Link utili  Adaptive filters for color image processing: A survey Image filters in Python Image manipulation using Numpy and SciPy How to build an image filter in Python Instagram filters in 15 lines of code. Il codice è disponibile qui.\n  ","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585177200,"objectID":"e1204e01d5855e2c2aaecda07ad247ec","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture3/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture3/","section":"courses","summary":"Manipolazione spaziale. Filtri. Convoluzione.\nSlides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], Ch. 3. [Gon18], Ch. 3. [Solem12], Ch. 1. [Sze11], sect. 3.2, 3.3. [Kin19], Ch. 2, 10-12.  Link utili  Adaptive filters for color image processing: A survey Image filters in Python Image manipulation using Numpy and SciPy How to build an image filter in Python Instagram filters in 15 lines of code.","tags":null,"title":"Filtri","type":"docs"},{"authors":null,"categories":null,"content":" Principali argomenti trattati:\n Introduzione ai Jupyter notebooks Caricamento di immagini con PIL Panoramica delle librerie e delle principali funzioni per effettuare trasformazioni geometriche, operazioni aritmetiche, edge detection.  Slides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 5. [Gon18], Ch. 3. [Solem12], Ch. 1. [Sze11], sect. 4.2. [Kin19], Ch. 13.  Link utili  OpenCV Scikit Image PIL tutorial Scikit Image Tutorial  ","date":1585177200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585177200,"objectID":"e7bbf53ec144d937b93432ddbaaef3d2","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture_lab1/","publishdate":"2020-03-26T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture_lab1/","section":"courses","summary":" Principali argomenti trattati:\n Introduzione ai Jupyter notebooks Caricamento di immagini con PIL Panoramica delle librerie e delle principali funzioni per effettuare trasformazioni geometriche, operazioni aritmetiche, edge detection.  Slides disponibili qui\nLa lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Davies18], ch. 5. [Gon18], Ch. 3. [Solem12], Ch. 1. [Sze11], sect. 4.2. [Kin19], Ch. 13.  Link utili  OpenCV Scikit Image PIL tutorial Scikit Image Tutorial  ","tags":null,"title":"Python \u0026 image processing","type":"docs"},{"authors":null,"categories":null,"content":" Derivate di immagini. Gradient-based filtering. trasformata di Fourier e Filtraggio.\nSlides disponibili:\n edge detection Fourier Transform  La lezione è corredata di due notebook:\n Edge detection Fourier Transform  Riferimenti bibliografici  [Davies18], ch. 5. [Gon18], Ch. 3, 4. [Solem12], Ch. 1. [Sze11], sect. 4.2. [Kin19], Ch. 10, 11, 13.  Link utili  Andrew Ng on Edge Detection: youtube lectures (1) e (2). Introduction to Edge Detection Concept of Image detection OpenCV Python Tutorial: Image Gradients Filtraggio con la trasformata  ","date":1585782000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585782000,"objectID":"ecda5c76dbdc18ffdcd65688d76882e5","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture4/","publishdate":"2020-04-02T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture4/","section":"courses","summary":" Derivate di immagini. Gradient-based filtering. trasformata di Fourier e Filtraggio.\nSlides disponibili:\n edge detection Fourier Transform  La lezione è corredata di due notebook:\n Edge detection Fourier Transform  Riferimenti bibliografici  [Davies18], ch. 5. [Gon18], Ch. 3, 4. [Solem12], Ch. 1. [Sze11], sect. 4.2. [Kin19], Ch. 10, 11, 13.  Link utili  Andrew Ng on Edge Detection: youtube lectures (1) e (2). Introduction to Edge Detection Concept of Image detection OpenCV Python Tutorial: Image Gradients Filtraggio con la trasformata  ","tags":null,"title":"Derivate. Edge Detection","type":"docs"},{"authors":null,"categories":null,"content":" Derivate di immagini. Gradient-based filtering. trasformata di Fourier e Filtraggio.\nSlides disponibili qui\nImportante La parte relativa allo studio dei feature descriptors riguarderà anche il primo esonero. I dettagli dell\u0026rsquo;esonero sono pubblicati nell\u0026rsquo;apposita pagina\nRiferimenti bibliografici  [Davies18], Ch. 6, 13. [Solem12], Ch. 2, 8. [Sze11], Ch. 4.1. [Kin19], Ch. 17.  Link utili  Introduction to Neural Networks Tutorial on Logistic Regression Course Notes on Optimization for Machine Learning and Mathematical Foundations of Data Science An Introduction to Machine Learning with scikit-learn Introduction to Feature Detection and Matching SIFT: Theory and Practice OpenCV Tutorials on Feature Descriptors  ","date":1585782000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585782000,"objectID":"22fdf08ffa64fff9c471507cc6e9651f","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture5/","publishdate":"2020-04-02T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture5/","section":"courses","summary":" Derivate di immagini. Gradient-based filtering. trasformata di Fourier e Filtraggio.\nSlides disponibili qui\nImportante La parte relativa allo studio dei feature descriptors riguarderà anche il primo esonero. I dettagli dell\u0026rsquo;esonero sono pubblicati nell\u0026rsquo;apposita pagina\nRiferimenti bibliografici  [Davies18], Ch. 6, 13. [Solem12], Ch. 2, 8. [Sze11], Ch. 4.1. [Kin19], Ch. 17.  Link utili  Introduction to Neural Networks Tutorial on Logistic Regression Course Notes on Optimization for Machine Learning and Mathematical Foundations of Data Science An Introduction to Machine Learning with scikit-learn Introduction to Feature Detection and Matching SIFT: Theory and Practice OpenCV Tutorials on Feature Descriptors  ","tags":null,"title":"Feature descriptors. Classificazione","type":"docs"},{"authors":null,"categories":null,"content":" Pytorch \u0026amp; SKlearn\nPrincipali argomenti trattati:\n Pre-process di un dataset e costruzione dei train/validation/test set SKLearn, regressione lineare e logistica Introduzione a Pytorch Costruzione di un modello di NN  La lezione è corredata di due notebook disponibili qui.\nRiferimenti bibliografici  [Davies18], ch. 13. [Elg20], ch. 2.  Link utili  SKLearn Pytorch MINIST dataset  ","date":1586214000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586214000,"objectID":"11198a798975f969a2d2653e4b7427e9","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture_lab2/","publishdate":"2020-04-07T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture_lab2/","section":"courses","summary":" Pytorch \u0026amp; SKlearn\nPrincipali argomenti trattati:\n Pre-process di un dataset e costruzione dei train/validation/test set SKLearn, regressione lineare e logistica Introduzione a Pytorch Costruzione di un modello di NN  La lezione è corredata di due notebook disponibili qui.\nRiferimenti bibliografici  [Davies18], ch. 13. [Elg20], ch. 2.  Link utili  SKLearn Pytorch MINIST dataset  ","tags":null,"title":"Pytorch, SKlearn and Classification","type":"docs"},{"authors":null,"categories":null,"content":" Grafi di computazione e modelli non lineari. Reti Convoluzionali. LeNet-5.\nMateriale didattico:\n Modelli non lineari (slides) Reti convoluzionali (slides) Notebook di accompagnamento  Riferimenti bibliografici  [Davies18], Ch. 15. [Gon18], Ch. 13. [Elg20], Ch. 2,3  Link utili  Introduction to Neural Networks\n Dive into Deep Learning\n Course Notes on Optimization for Machine Learning and Mathematical Foundations of Data Science\n Understanding graphs and automatic differentiation\n Yes you should understand backpropagation\n Visualizing and understanding convolutional Networks\n Vincent Dumoulin, Francesco Visin - A guide to convolution arithmetic for deep learning]\n An illustrated explanation of performing 2D convolution using matrix multiplication. Un esempio illustrativo anche su slideshare.\n Visualizing neural networks using saliency maps. Reference paper su arxiv.\n Saliency maps in Flashtorch. Medium description.\n A collection of Deep network visualization techniques in Pytorch\n  ","date":1587164400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587164400,"objectID":"4290bb6d65bef0cba51704cf9b042474","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture6/","publishdate":"2020-04-18T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture6/","section":"courses","summary":"Grafi di computazione e modelli non lineari. Reti Convoluzionali. LeNet-5.\nMateriale didattico:\n Modelli non lineari (slides) Reti convoluzionali (slides) Notebook di accompagnamento  Riferimenti bibliografici  [Davies18], Ch. 15. [Gon18], Ch. 13. [Elg20], Ch. 2,3  Link utili  Introduction to Neural Networks\n Dive into Deep Learning\n Course Notes on Optimization for Machine Learning and Mathematical Foundations of Data Science\n Understanding graphs and automatic differentiation","tags":null,"title":"Neural Networks","type":"docs"},{"authors":null,"categories":null,"content":" Object detection.\n Region Proposal Networks: R-CNN, Fast R-CNN, Faster R-CNN. Single Shot Detectors: SSD, RetinaNet, YOLO.  Materiale didattico:\n slides Notebook di accompagnamento Demo YOLO  Riferimenti bibliografici  [Elg20], Ch. 7  Link utili  An overview of Deep-Learning based Object Detection algorithms\n Rich Feature-Based hierarchies for accurate object detection and semantic segmentation\n Fast R-CNN\n Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\n Faster R-CNN tutorials: A guide to building Faster R-CNN in Pytorch e Detecting objects in (almost) Real time\n SSD: Single Shot MultiBox Detector\n SSD Tutorial\n Detectron and Detectron2\n You Only Look Once: YOLOv1, YOLOv2, YOLOv3\n Understanding YOLO\n What\u0026rsquo;s new in YOLOv3?\n Speed and accuracy comparison in object detection\n YOLOv4 paper (with code)\n YOLOv4 - Superior, faster and more accurate\n YOLOv4 in Pytorch\n Focal Loss for Dense Object Detection\n Review - RetinaNet\n RetinaNet explained and demystified\n 5 tools to create a custom object detection dataset\n NEW DETR: End-to-end object detection with Transformers\n  ","date":1588028400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588028400,"objectID":"b40b6a924aaa40ef82e592f94f92d747","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture7/","publishdate":"2020-04-28T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture7/","section":"courses","summary":"Object detection.\n Region Proposal Networks: R-CNN, Fast R-CNN, Faster R-CNN. Single Shot Detectors: SSD, RetinaNet, YOLO.  Materiale didattico:\n slides Notebook di accompagnamento Demo YOLO  Riferimenti bibliografici  [Elg20], Ch. 7  Link utili  An overview of Deep-Learning based Object Detection algorithms\n Rich Feature-Based hierarchies for accurate object detection and semantic segmentation\n Fast R-CNN\n Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks","tags":null,"title":"Object Detection","type":"docs"},{"authors":null,"categories":null,"content":" Principali argomenti trattati:\n AlexNet VGG Residual Network Inception Network Data Augmentation Transfer Learning  La lezione è corredata di slides e di un notebook disponibile qui.\nImportante Il secondo esonero riguarderà approfondimenti sulle reti convoluzionali. I dettagli dell\u0026rsquo;esonero sono pubblicati nell\u0026rsquo;apposita pagina.\nRiferimenti bibliografici  [Davies18], ch. 15. [Elg20], ch. 4.6, 5, 6.  Link utili  Yann LeCun\u0026rsquo;s page on LeNet (with papers and description). ImageNet Classification with Deep Convolutional Neural Networks\n Local Response Norm vs. Bach Norm\n Very Deep Convolutional Networks for Large Scale Image Recognition\n Going Deeper with Convolutions\n A simple guide to the versions of Inception Networks\n Batch normalization: accelerating deep network training by reducing internal covariate shift\n Residual Learning for image Recognition\n How transferable are features in deep neural networks?\n Torch pretrained models\n TorchHUB\n Caltech101 dataset\n Survey on data augmentation technique\n  ","date":1587682800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587682800,"objectID":"f473dfcf3b80627a8fc133d7a6f4129d","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture_lab3/","publishdate":"2020-04-24T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture_lab3/","section":"courses","summary":"Principali argomenti trattati:\n AlexNet VGG Residual Network Inception Network Data Augmentation Transfer Learning  La lezione è corredata di slides e di un notebook disponibile qui.\nImportante Il secondo esonero riguarderà approfondimenti sulle reti convoluzionali. I dettagli dell\u0026rsquo;esonero sono pubblicati nell\u0026rsquo;apposita pagina.\nRiferimenti bibliografici  [Davies18], ch. 15. [Elg20], ch. 4.6, 5, 6.  Link utili  Yann LeCun\u0026rsquo;s page on LeNet (with papers and description). ImageNet Classification with Deep Convolutional Neural Networks","tags":null,"title":"CNN Architectures","type":"docs"},{"authors":null,"categories":null,"content":" Principali argomenti trattati:\n Anchor box SSD YOLOv3 RetinaNet  La lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Elg20], ch. 7. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., \u0026amp; Berg, A. C. (2016). Ssd: single shot multibox detector. European conference on computer vision (pp. 21–37).  Link utili  SSD tutorial RetinaNet in pytorch Retinanet Paper YOLOv4 FocalLoss tutorial YOLOv3 example  ","date":1588633200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588633200,"objectID":"18bb770274a850b7647ee5176a77282f","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture_lab4/","publishdate":"2020-05-05T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture_lab4/","section":"courses","summary":" Principali argomenti trattati:\n Anchor box SSD YOLOv3 RetinaNet  La lezione è corredata di un notebook disponibile qui\nRiferimenti bibliografici  [Elg20], ch. 7. Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.-Y., \u0026amp; Berg, A. C. (2016). Ssd: single shot multibox detector. European conference on computer vision (pp. 21–37).  Link utili  SSD tutorial RetinaNet in pytorch Retinanet Paper YOLOv4 FocalLoss tutorial YOLOv3 example  ","tags":null,"title":"Object Detection","type":"docs"},{"authors":null,"categories":null,"content":"  Segmentation.\n Approcci classici. Conditional Random Fields. slides. Approcci Neurali. Semantic Segmentation. Instance Segmentation. slides. Notebook di accompagnamento.   Riferimenti bibliografici  [Sze11], Ch. 5 [Davies18], Ch.11 [Gon18], Ch.10  Link utili  An Introduction to Conditional Random Fields\n Structured Learning and Prediction in Computer Vision\n An experimental Comparison of Min-cut/Max Flow algorithms for Energy Minimization in Vision\n Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials (with Supplemental Material)\n Conditional Random Fields explained\n Introduction to Conditional Random Fields\n A simple guide to semantic Segmentation and A 2019 guide to semantic segmentation\n Fully Convolutional Networks for Semantic Segmentation\n Review - FCN\n Upsampling with Transposed Convolution; Transposed Convolution demystified; Transposed convolutions explained with Excel\n Deconvolution and checkerboard artifacts\n Learning Deconvolution Network for Semantic Segmentation\n SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation]\n U-Net: Convolutional Networks for Biomedical Image Segmentation\n The One Hundred Layers Tiramisu\n Pyramid scene parsing Networks\n DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\n Multiscale Context aggregation by dilated convolutions\n Rethinking Atrous Convolution for Semantic Image Segmentation\n Review: DeepLabv2 e DeepLabv3\n Speeding up Semantic segmentation for autonomous driving\n ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation\n ICNet for Real-Time Semantic Segmentation on High-Resolution Images\n Fast-SCNN: Fast Semantic Segmentation Network\n DFANet: Deep Feature Aggregation for Real-Time Semantic Segmentation\n Mask R-CNN\n Image Segmentation with Mask R-CNN\n Fully Convolutional Instance-aware Semantic Segmentation\n YOLACT and YOLOACT++\n Pantropic Segmentation\n  ","date":1589238000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589238000,"objectID":"d128349c734f57f98654f9c9a68f561b","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture8/","publishdate":"2020-05-12T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture8/","section":"courses","summary":"Segmentation.\n Approcci classici. Conditional Random Fields. slides. Approcci Neurali. Semantic Segmentation. Instance Segmentation. slides. Notebook di accompagnamento.   Riferimenti bibliografici  [Sze11], Ch. 5 [Davies18], Ch.11 [Gon18], Ch.10  Link utili  An Introduction to Conditional Random Fields\n Structured Learning and Prediction in Computer Vision\n An experimental Comparison of Min-cut/Max Flow algorithms for Energy Minimization in Vision\n Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials (with Supplemental Material)","tags":null,"title":"Segmentation","type":"docs"},{"authors":null,"categories":null,"content":"  Action Recognition.\n 3D Convolution. Recurrent Networks. Optical Flow. slides. Notebook di accompagnamento.   Riferimenti bibliografici  [Sze11], Ch. 8 [Davies18], Ch.20  Link utili  Deep Learning for Action Recognition: A Review 3D Convolution in Pytorch Learning Spatiotemporal Features with 3D Convolutional Networks Quo vadis, action recognition? a new model and the kinetics dataset 3d convolutional neural networks for human action recognition Large-Scale Video Classification with Convolutional Neural Networks Learning spatio-temporal representation with pseudo-3d residual networks Rethinking Spatiotemporal Feature Learning Spatiotemporal residual networks for video action recognition Long-Term Feature Banks for Detailed Video Understanding The Kinetics Human Action Recognition Dataset Long-term Recurrent Convolutional Networks for Visual Recognition and Description Action Recognition Using Visual Attention Recurrent Tubelet Proposal and Recognition Networks for Action Detection VideoLSTM Convolves, Attends and Flows for Action Recognition Beyond Short Snippets: Deep Networks for Video Classification An Iterative Image Registration Technique with an Application to Stero Vision Two-Frame Motion Estimation with Polynomial Expansion Introduction to Motion Estimation with Optical Flow Optical Flow Estimation FlowNet: Learning Optical Flow with Convolutional Networks Two-Stream Convolutional Networks for Action Recognition in Videos What is optical flow and why does it matter in deep learning Michael Black\u0026rsquo;s lecture on Optical Flow  ","date":1589842800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589842800,"objectID":"cb0cb82d1c264778fac8fd32556a21a8","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture9/","publishdate":"2020-05-19T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture9/","section":"courses","summary":"  Action Recognition.\n 3D Convolution. Recurrent Networks. Optical Flow. slides. Notebook di accompagnamento.   Riferimenti bibliografici  [Sze11], Ch. 8 [Davies18], Ch.20  Link utili  Deep Learning for Action Recognition: A Review 3D Convolution in Pytorch Learning Spatiotemporal Features with 3D Convolutional Networks Quo vadis, action recognition? a new model and the kinetics dataset 3d convolutional neural networks for human action recognition Large-Scale Video Classification with Convolutional Neural Networks Learning spatio-temporal representation with pseudo-3d residual networks Rethinking Spatiotemporal Feature Learning Spatiotemporal residual networks for video action recognition Long-Term Feature Banks for Detailed Video Understanding The Kinetics Human Action Recognition Dataset Long-term Recurrent Convolutional Networks for Visual Recognition and Description Action Recognition Using Visual Attention Recurrent Tubelet Proposal and Recognition Networks for Action Detection VideoLSTM Convolves, Attends and Flows for Action Recognition Beyond Short Snippets: Deep Networks for Video Classification An Iterative Image Registration Technique with an Application to Stero Vision Two-Frame Motion Estimation with Polynomial Expansion Introduction to Motion Estimation with Optical Flow Optical Flow Estimation FlowNet: Learning Optical Flow with Convolutional Networks Two-Stream Convolutional Networks for Action Recognition in Videos What is optical flow and why does it matter in deep learning Michael Black\u0026rsquo;s lecture on Optical Flow  ","tags":null,"title":"Action Recognition","type":"docs"},{"authors":null,"categories":null,"content":"  Modelli Generativi: Variational Autoencoders. Slides  Notebook di accompagnamento.   Link utili  Autoencoding Variational Bayes Stochastic Backpropagation and Approximate Inference in Deep Generative Models What is a Variational Autoencoder Variational Autoencoder for Deep Learning of Images, Labels and Captions Towards Visually Explaining Variational Autoencoders Understanding VAEs Improved Variational Inference with Inverse Autoregressive Flow Semi-supervised Variational Autoencoders Deep Generative Models Generative Models $\\beta$-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework  ","date":1590015600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590015600,"objectID":"c931d94842164c32620b9cb46364b8b6","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture10/","publishdate":"2020-05-21T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture10/","section":"courses","summary":"  Modelli Generativi: Variational Autoencoders. Slides  Notebook di accompagnamento.   Link utili  Autoencoding Variational Bayes Stochastic Backpropagation and Approximate Inference in Deep Generative Models What is a Variational Autoencoder Variational Autoencoder for Deep Learning of Images, Labels and Captions Towards Visually Explaining Variational Autoencoders Understanding VAEs Improved Variational Inference with Inverse Autoregressive Flow Semi-supervised Variational Autoencoders Deep Generative Models Generative Models $\\beta$-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework  ","tags":null,"title":"Modelli Generativi","type":"docs"},{"authors":null,"categories":null,"content":"  Modelli Generativi: Adversarial Learning. Slides  Notebook di accompagnamento.   Riferimenti bibliografici  [Elg20], Ch. 8, 9.3.  Link utili  Deep Generative Models Generative Adversarial Networks Understanding Generative Adversarial Networks Improved Techniques for training GANs How (not) to train your Generative Model: Scheduled Sampling, Likelihood, Adversary? GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium Do GAN actually Learn the Distribution? Progressive Growing of GANs for Improved Quality, Stability and Variation Are GANs Created Equal? A Large-Scale Study Wasserstein GANs Wasserstein GANs: Blog posts 1, 2, 3, 4 Improved training fo Wasserstein GANs (with some tricks on how to implement it in Pytorch) A collection of Generative Models in Pytorch How to train a GAN? (video) MSG-GAN: Multi-Scale Gradients for Generative Adversarial Networks Conditional Generative Adversarial Networks Image to image translation with Conditional Adversarial Networks A gentle introduction to CycleGAN for Image Translation Unpaired Image-to-image Translation using Cycle-Consistent Adversarial Networks Augmented Cyclic Adversarial Learning for Low Resource Domain Adaptation Understanding and Implementing CycleGAN Conditional Image Synthesis with Auxiliary Classifier GANs An Introduction to Image Synthesis with Generative Adversarial Nets Large-Scale GAN Training for High-Fidelity Natural Image Synthesis GANs for Medical Image Analysis The GAN Zoo GAN and Deepfakes resources How deep learning fakes videos and how to detect it Deepfakes: The ugly, and the good Deepfake Videos: GAN synthesizes a Video from a Single Photo Neural Style Transfer Tutorial A Neural algorithm of Artistic Style A Deep Journey into Superresolution  ","date":1590361200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590361200,"objectID":"e4c013dd34f716e937d2331cfa86d058","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture11/","publishdate":"2020-05-25T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture11/","section":"courses","summary":"Modelli Generativi: Adversarial Learning. Slides  Notebook di accompagnamento.   Riferimenti bibliografici  [Elg20], Ch. 8, 9.3.  Link utili  Deep Generative Models Generative Adversarial Networks Understanding Generative Adversarial Networks Improved Techniques for training GANs How (not) to train your Generative Model: Scheduled Sampling, Likelihood, Adversary? GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium Do GAN actually Learn the Distribution? Progressive Growing of GANs for Improved Quality, Stability and Variation Are GANs Created Equal?","tags":null,"title":"Generative Adversarial Networks","type":"docs"},{"authors":null,"categories":null,"content":" Principali argomenti trattati:\n CycleGAN DeepFake  La lezione è corredata di slide disponibili qui\nLink utili  CycleGAN Pytorch implementation CycleGAN intro DeepFake - face swap DeepFake  ","date":1587596400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587596400,"objectID":"2c583abe08f83005dd7ff1f67929494d","permalink":"https://gmanco.github.io/courses/computervision/2020/lecture_lab5/","publishdate":"2020-04-23T00:00:00+01:00","relpermalink":"/courses/computervision/2020/lecture_lab5/","section":"courses","summary":" Principali argomenti trattati:\n CycleGAN DeepFake  La lezione è corredata di slide disponibili qui\nLink utili  CycleGAN Pytorch implementation CycleGAN intro DeepFake - face swap DeepFake  ","tags":null,"title":"CycleGAN and DeepFake","type":"docs"},{"authors":null,"categories":null,"content":" Feature descriptors In questo esonero è chiesto agli studenti di sperimentare con un feature descriptr tra quelli elencati in seguito. In particolare si chiede di:\n Scegliere un feature descriptor Preparare delle slides dettagliate (max 15) che lo descrivono Preparare un notebook in cui:  si implementa l\u0026rsquo;algoritmo che sta alla slide 62 (istogramma basato sui feature descriptors) si applica la regressione logistica (da scikit-learn) sul set di immagini (MNIST) si valutano i risultati della classificazione confrontandoli con la regressione logistica applicata alla flattenizzazione raw dell\u0026rsquo;immagine (opportunamente preprocessata).   Gli studenti interessati ad effettuare l\u0026rsquo;esonero dovranno mandare una mail al docente indicando, in ordine di priorità, tre scelte dalla lista di cui sotto. Le assegnazioni verranno comunicate a lezione. La deadline per la consegna degli elaborati è il 16 aprile 2020.\nOpenCV Tutorials disponibili qui.\n SIFT, Class for extracting keypoints and computing descriptors using the Scale Invariant Feature Transform (SIFT) algorithm by D. Lowe. Riferimenti: David G Lowe. Distinctive image features from scale-invariant keypoints. International journal of computer vision, 60(2):91–110, 2004. SURF, Class for extracting Speeded Up Robust Features from an image. Riferimenti: Herbert Bay, Tinne Tuytelaars, and Luc Van Gool. Surf: Speeded up robust features. Computer Vision–ECCV 2006, pages 404–417, 2006. AKAZE, Class implementing the AKAZE keypoint detector and descriptor extractor. Riferimenti: Pablo F Alcantarilla, Jesús Nuevo, and Adrien Bartoli. Fast explicit diffusion for accelerated features in nonlinear scale spaces. Trans. Pattern Anal. Machine Intell, 34(7):1281–1298, 2011. Brisk, Class implementing the BRISK keypoint detector and descriptor extractor. [Stefan Leutenegger, Margarita Chli, and Roland Yves Siegwart. Brisk: Binary robust invariant scalable keypoints. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 2548–2555. IEEE, 2011. Mser, Maximally stable extremal region extractor, for grey scale and color image. Riferimenti: David Nistér and Henrik Stewénius. Linear time maximally stable extremal regions. In Computer Vision–ECCV 2008, pages 183–196. Springer, 2008.; Per-Erik Forssén. Maximally stable colour regions for recognition and matching. In Computer Vision and Pattern Recognition, 2007. CVPR\u0026rsquo;07. IEEE Conference on, pages 1–8. IEEE, 2007. ORB, The algorithm uses FAST in pyramids to detect stable keypoints, selects the strongest features using FAST or Harris response, finds their orientation using first-order moments and computes the descriptors using BRIEF (where the coordinates of random point pairs (or k-tuples) are rotated according to the measured orientation). Riferimenti: Ethan Rublee, Vincent Rabaud, Kurt Konolige, and Gary Bradski. Orb: an efficient alternative to sift or surf. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages 2564–2571. IEEE, 2011.  SK-Image Documentation at the home page of the scikit-image feature description package.\n skimage.feature.daisy, Extract DAISY feature descriptors densely for the given image. DAISY is a feature descriptor similar to SIFT formulated in a way that allows for fast dense extraction. Typically, this is practical for bag-of-features image representations. Riferimenti: Tola et al. Daisy: An efficient dense descriptor applied to wide- baseline stereo. Pattern Analysis and Machine Intelligence, IEEE Transactions on 32.5 (2010): 815-830.] skimage.feature.hog, Extract Histogram of Oriented Gradients (HOG) for a given image. Riferimenti: Dalal, N and Triggs, B, Histograms of Oriented Gradients for Human Detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2005 San Diego, CA, USA, DOI:10.1109/CVPR.2005.177] skimage.feature.local_binary_pattern, Gray scale and rotation invariant LBP (Local Binary Patterns). Riferimenti: Timo Ojala, Matti Pietikainen, Topi Maenpaa. Multiresolution Gray-Scale and Rotation Invariant Texture Classification with Local Binary Patterns. 2002] skimage.feature.haar_like_feature, Compute the Haar-like features for a region of interest (ROI) of an integral image. Riferimenti: Messom, Christopher H. and Andre L. C. Barczak. Stream processing for fast and efficient rotated Haar-like features using rotated integral images. IJISTA 7 (2006): 40-57. skimage.feature.BRIEF, BRIEF binary descriptor extractor. BRIEF (Binary Robust Independent Elementary Features) is an efficient feature point descriptor. It is highly discriminative even when using relatively few bits and is computed using simple intensity difference tests. Riferimenti: Calonder, Michael \u0026amp; Lepetit, Vincent \u0026amp; Strecha, Christoph \u0026amp; Fua, Pascal. (2010). BRIEF: Binary Robust Independent Elementary Features. Eur. Conf. Comput. Vis.. 6314. 778-792. 10.1007\u0026frasl;978-3-642-15561-1_56.\n skimage.feature.ORB, Oriented FAST and rotated BRIEF feature detector and binary descriptor extractor. Riferimenti: Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski. ORB: An efficient alternative to SIFT and SURF.  Assegnazioni  Giulia Katia Galimberti SIFT (OpenCV) Maria Francesca Alati skimage.feature.hog Lorenzo Defina Mser (OpenCV) Emilio Casella Surf (OpenCV) Simona Nisticò matricola ORB (OpenCV) Domenico Montesanto AKAZE (OpenCV) Caterina Maugeri skimage.feature.local_binary_pattern Giuseppe Surace skimage.feature.haar_like_feature Antonello Crea Daisy (OpenCV) Anile Anna skimage.feature.BRIEF Vincenzo Parrilla SURF with Harris Corner Detection. (OpenCV) Davide Medaglia SIFT with Harris Corner Detection (OpenCV) Antonio Commisso Brisk (OpenCV) Antonio Gagliostro: skimage.feature.ORB  Risultati    Studente Voto     Alati Maria Francesca 8   Anile Anna 8   Casella Emilio 7   Commisso Antonio 7   Crea Antonello 10   Defina Lorenzo 6   Gagliostro Antonio 9   Galimberti Giulia 5   Maugeri Caterina 8   Medaglia Davide 8   Montesanto Domenico 7   Nisticò Simona 9   Parrilla Vincenzo 7   Surace Giuseppe 4    ","date":1585782000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585782000,"objectID":"e5bc5d5de1ae6e738848945df9880b39","permalink":"https://gmanco.github.io/courses/computervision/2020/esoneri/listoffeaturedescriptors/","publishdate":"2020-04-02T00:00:00+01:00","relpermalink":"/courses/computervision/2020/esoneri/listoffeaturedescriptors/","section":"courses","summary":"Feature descriptors In questo esonero è chiesto agli studenti di sperimentare con un feature descriptr tra quelli elencati in seguito. In particolare si chiede di:\n Scegliere un feature descriptor Preparare delle slides dettagliate (max 15) che lo descrivono Preparare un notebook in cui:  si implementa l\u0026rsquo;algoritmo che sta alla slide 62 (istogramma basato sui feature descriptors) si applica la regressione logistica (da scikit-learn) sul set di immagini (MNIST) si valutano i risultati della classificazione confrontandoli con la regressione logistica applicata alla flattenizzazione raw dell\u0026rsquo;immagine (opportunamente preprocessata).","tags":null,"title":"Esonero 1","type":"docs"},{"authors":null,"categories":null,"content":" Convolutional Neural Networks In questo esonero è chiesto agli studenti di studiare le reti convoluzionali.\n Scegliere un topic Preparare delle slides dettagliate (max 15) che lo descrivono Preparare un notebook in cui:  si implementa quello che è richiesto si illustrano i risultati e la loro valutazione   Gli studenti interessati ad effettuare l\u0026rsquo;esonero dovranno mandare una mail al docente indicando, in ordine di priorità, tre scelte dalla lista di cui sotto. Le assegnazioni verranno comunicate a lezione. La deadline per la consegna degli elaborati è il 10 maggio 2020.\nGoogLeNet  Scegliere una delle seguenti varianti di GoogLeNet e implementarla, riaddestrando la rete su CIFAR-10 e mostrando i risultati.  Utilizzare i layer di batch normalization [Ioffe \u0026amp; Szegedy, 2015] Effettuare gli aggiustamenti all\u0026rsquo;inception block suggeriti in [Szegedy et al., 2016]. effettuare gli aggiustamenti alle residual connections suggerite in [Szegedy et al., 2017],  Qual\u0026rsquo;è la dimensione minima richiesta per l\u0026rsquo;immagine di input in GoogLeNet?   Ioffe, S., \u0026amp; Szegedy, C. (2015). Batch normalization: accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., \u0026amp; Wojna, Z. (2016). Rethinking the inception architecture for computer vision. Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 2818–2826). Szegedy, C., Ioffe, S., Vanhoucke, V., \u0026amp; Alemi, A. A. (2017). Inception-v4, inception-resnet and the impact of residual connections on learning. Thirty-First AAAI Conference on Artificial Intelligence.  ResNet  Nelle versioni successive di ResNet, gli autori hanno cambiato l\u0026rsquo;architettura da “convolution, batch normalization, activation” in “batch normalization, activation, convolution”. Studia gli effetti di questo cambiamento nell\u0026rsquo;implementazione proposta in classe, ristrutturando la rete e riaddestrandola su CIFAR-10. [He et al., 2016] Qual\u0026rsquo;è la dimensione minima richiesta per l\u0026rsquo;immagine di input in ResNet ?   He, K., Zhang, X., Ren, S., \u0026amp; Sun, J. (2016). Identity mappings in deep residual networks. European conference on computer vision (pp. 630–645).  Saliency Maps using Flashtorch Studiare l\u0026rsquo;articolo [Simonyan et al, 2014] e il package flashtorch e usalo su alcune reti preaddestrate (VGG16, GoogLeNet, ResNet).\n Karen Simonyan, Andrea Vedaldi, Andrew Zisserman. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. ICLR2014 Visualize image specific class saliency with backprop  Alternative alla Batch Normalization Prendere come riferimento la rete VGG16. Si studino gli effetti della normalizzazione riaddestrando la rete su CIFAR-10:\n Aggiungendo Batch Normalization Aggiungendo Local Response Normalization Implementando la tecnica di Group Normalization descritta in [Wu et al, 2018]   Y. Wu, K. He. Group Normalization. An alternative to Batch Normalization  Assegnazioni  Costa Davide Alternative alla Batch Normalization Azzato Saverio GoogleLeNet (aggiustamenti all’inception block) Sergi Alfredo GoogLeNet (aggiustamenti alle residual connection) De Prete Alessandra Saliency Maps using Flashtorch Prospero Papaleo ResNet Lavecchia Umberto Mattia GoogLeNet (con studio sulla batch normalization)  Risultati    Studente Voto     Azzato Saverio 7   Costa Davide 10   Del Prete Alessandra 10   Lavecchia Mattia 5   Papaleo Prospero 6   Sergi Alfredo 7    ","date":1588028400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588028400,"objectID":"cae2dc59be0f65db10651a4077c74fac","permalink":"https://gmanco.github.io/courses/computervision/2020/esoneri/convolution/","publishdate":"2020-04-28T00:00:00+01:00","relpermalink":"/courses/computervision/2020/esoneri/convolution/","section":"courses","summary":"Convolutional Neural Networks In questo esonero è chiesto agli studenti di studiare le reti convoluzionali.\n Scegliere un topic Preparare delle slides dettagliate (max 15) che lo descrivono Preparare un notebook in cui:  si implementa quello che è richiesto si illustrano i risultati e la loro valutazione   Gli studenti interessati ad effettuare l\u0026rsquo;esonero dovranno mandare una mail al docente indicando, in ordine di priorità, tre scelte dalla lista di cui sotto.","tags":null,"title":"Esonero 2","type":"docs"},{"authors":null,"categories":null,"content":" Specifiche\n Action Recognition in ambito sportivo\n Task: individuare 10 tipologie di azioni di basket\n Costruire un modello di classificazione\n  Dataset  Il dataset è composto da 32557 clip (MP4, 16 frame RGB) di azioni di basket. Il dataset è suddiviso in train (22779) e test (9778)\n Il test set è utilizzato per la valutazione, le clip (DA NON UTILIZZARE NEL TRAINING) sono definite in un file allegato a queste slide.\n Tipologia di azioni possibili (10 classi)\n Download: https://drive.google.com/open?id=1hLpbLmLFK2-GIvsmpJelGlEx94yQM2Ts\n  Requisiti  Definire e addestrare un modello di classificazione Descrivere in una relazione/presentazione le scelte progettuali e tutti i parametri utilizzati nella sperimentazione. Consegnare notebook (e/o file sorgente), relazione e dump del modello  Protocollo di valutazione  Valutazione generale del progetto\n Loading del modello e calcolo delle precisione media sul test set\n  Baseline-1 - 8 pt – Valore 0.40 Baseline-2 - 7 pt – Valore 0.60\nPer accedere all’orale sono necessari almeno 8 pt.\nAssegnazione dei punteggi:  Se il modello supera la Baseline-1: 8 pt Se il modello non supera la Baseline-2: (p – Baseline-1)/(Baseline-2 - Baseline-1) * 7 pt Se il modello supera la Baseline-2: 7 pt + bonus Bonus (p – Baseline-2)/(BESTMODEL - Baseline-2) * 5 pt  Appelli  1 – luglio – Progetto attuale\n Consegna entro domenica 28 giugno\n 31 – luglio – Nuovo Progetto (stesse modalità)\n Rilascio indicativo fine giugno   Per ulteriori info vedere qui\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e7f78bbe4b60d7b765fdb84973ee616f","permalink":"https://gmanco.github.io/courses/computervision/2020/progetti/project1_spec/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/computervision/2020/progetti/project1_spec/","section":"courses","summary":"Specifiche\n Action Recognition in ambito sportivo\n Task: individuare 10 tipologie di azioni di basket\n Costruire un modello di classificazione\n  Dataset  Il dataset è composto da 32557 clip (MP4, 16 frame RGB) di azioni di basket. Il dataset è suddiviso in train (22779) e test (9778)\n Il test set è utilizzato per la valutazione, le clip (DA NON UTILIZZARE NEL TRAINING) sono definite in un file allegato a queste slide.","tags":null,"title":"Progetto 1","type":"docs"},{"authors":null,"categories":null,"content":" Specifiche\n Action Recognition in ambito sportivo\n Task: individuare 10 tipologie di azioni di basket\n Costruire un modello di classificazione\n  Dataset Si utilizza lo stesso dataset dell\u0026rsquo;appello precedente (appello precedente) con lo stesso protocollo di valutazione e le baseline riportate di seguito.\n Principali differenze rispetto all\u0026rsquo;appello precedente:\n nuovo test set nuovi valori baseline oltre al materiale già indicato, è necessario consegnare anche una presentazione da mostrare durante l\u0026rsquo;esame   Requisiti  Definire e addestrare un modello di classificazione Descrivere in una presentazione le scelte progettuali e tutti i parametri utilizzati nella sperimentazione. Consegnare notebook (e/o file sorgente), PRESENTAZIONE e dump del modello  Protocollo di valutazione  Valutazione generale del progetto\n Loading del modello e calcolo delle precisione media sul test set\nBaseline-1 - 8 pt – Valore 0.65 Baseline-2 - 7 pt – Valore 0.70 Per accedere all’orale sono necessari almeno 8 pt. Assegnazione dei punteggi: Se il modello supera la Baseline-1: 8 pt Se il modello non supera la Baseline-2: (p – Baseline-1)/(Baseline-2 - Baseline-1) * 7 pt Se il modello supera la Baseline-2: 7 pt + bonus Bonus (p – Baseline-2)/(BESTMODEL - Baseline-2) * 5 pt   Nuovo TestSet\nPer costruire il test set utilizzare le chiavi fornite nel file testset_keys_1lug2020.txt\nMD5 (testset_keys_1lug2020.txt) = d66ed18631567fdf3069cbd7fc9e5de1  Appello\n Data Rilascio 01/07/2020 Data Consegna 29/07/2020 ore 12.00 Data Appello 31/07/2020  Per ulteriori info vedere https://github.com/gmanco/cv_notebooks/tree/master/project_2\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3c3662b714d6516cc061f2e132ea5c09","permalink":"https://gmanco.github.io/courses/computervision/2020/progetti/project2_spec/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/computervision/2020/progetti/project2_spec/","section":"courses","summary":"Specifiche\n Action Recognition in ambito sportivo\n Task: individuare 10 tipologie di azioni di basket\n Costruire un modello di classificazione\n  Dataset Si utilizza lo stesso dataset dell\u0026rsquo;appello precedente (appello precedente) con lo stesso protocollo di valutazione e le baseline riportate di seguito.\n Principali differenze rispetto all\u0026rsquo;appello precedente:\n nuovo test set nuovi valori baseline oltre al materiale già indicato, è necessario consegnare anche una presentazione da mostrare durante l\u0026rsquo;esame   Requisiti  Definire e addestrare un modello di classificazione Descrivere in una presentazione le scelte progettuali e tutti i parametri utilizzati nella sperimentazione.","tags":null,"title":"Progetto 2","type":"docs"},{"authors":null,"categories":null,"content":" Specifiche\n Action Recognition in ambito sportivo\n Task: individuare 10 tipologie di azioni di basket\n Costruire un modello di classificazione\n  Dataset Si utilizza lo stesso dataset dell\u0026rsquo;appello precedente (appello precedente) con lo stesso protocollo di valutazione e le baseline riportate di seguito.\n Principali differenze rispetto all\u0026rsquo;appello precedente:\n nuovo test set nuovi valori baseline oltre al materiale già indicato, è necessario consegnare anche una presentazione da mostrare durante l\u0026rsquo;esame   Requisiti  Definire e addestrare un modello di classificazione Descrivere in una presentazione le scelte progettuali e tutti i parametri utilizzati nella sperimentazione. Consegnare notebook (e/o file sorgente), PRESENTAZIONE e dump del modello  Protocollo di valutazione  Valutazione generale del progetto\n Loading del modello e calcolo delle precisione media sul test set\nBaseline-1 - 8 pt – Valore 0.75 Baseline-2 - 7 pt – Valore 0.80 Per accedere all’orale sono necessari almeno 8 pt. Assegnazione dei punteggi: Se il modello supera la Baseline-1: 8 pt Se il modello non supera la Baseline-2: (p – Baseline-1)/(Baseline-2 - Baseline-1) * 7 pt Se il modello supera la Baseline-2: 7 pt + bonus Bonus (p – Baseline-2)/(BESTMODEL - Baseline-2) * 5 pt   Nuovo TestSet\nPer costruire il test set utilizzare le chiavi fornite nel file testset_keys_1lug2020.txt\nMD5 (testset_keys_1lug2020.txt) = d66ed18631567fdf3069cbd7fc9e5de1  Appello\n Data Rilascio 31/07/2020 Data Consegna 01/09/2020 ore 12.00 Data Appello 03/09/2020 ore 9.00  Per ulteriori info vedere https://github.com/gmanco/cv_notebooks/tree/master/project_3\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"da43d288c3336abccc1a90b044810769","permalink":"https://gmanco.github.io/courses/computervision/2020/progetti/project3_spec/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/courses/computervision/2020/progetti/project3_spec/","section":"courses","summary":"Specifiche\n Action Recognition in ambito sportivo\n Task: individuare 10 tipologie di azioni di basket\n Costruire un modello di classificazione\n  Dataset Si utilizza lo stesso dataset dell\u0026rsquo;appello precedente (appello precedente) con lo stesso protocollo di valutazione e le baseline riportate di seguito.\n Principali differenze rispetto all\u0026rsquo;appello precedente:\n nuovo test set nuovi valori baseline oltre al materiale già indicato, è necessario consegnare anche una presentazione da mostrare durante l\u0026rsquo;esame   Requisiti  Definire e addestrare un modello di classificazione Descrivere in una presentazione le scelte progettuali e tutti i parametri utilizzati nella sperimentazione.","tags":null,"title":"Progetto 3","type":"docs"},{"authors":["Antonio L. Alfeo","Mario G.C.A. Cimino","Giuseppe Manco","Ettore Ritacco","Gigliola Vaglini"],"categories":null,"content":"","date":1593388800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593388800,"objectID":"854fb9eb33bf2ce04d527f8c29b4d8cc","permalink":"https://gmanco.github.io/publication/alfeo-2020/","publishdate":"2020-05-29T11:18:44.874439Z","relpermalink":"/publication/alfeo-2020/","section":"publication","summary":"According to the smart manufacturing paradigm, the analysis of assets’ time series with a machine learning approach can effectively prevent unplanned production downtimes by detecting assets’ anomalous operational conditions. To support smart manufacturing operators with no data science background, we propose an anomaly detection approach based on deep learning and aimed at providing a manageable machine learning pipeline and easy to interpret outcome. To do so we combine (i) an autoencoder, a deep neural network able to produce an anomaly score for each provided time series, and (ii) a discriminator based on a general heuristics, to automatically discern anomalies from regular instances. We prove the convenience of the proposed approach by comparing its performances against isolation forest with different case studies addressing industrial laundry assets’ power consumption and bearing vibrations.","tags":["Fault Detection","Anomaly Detection","Smart Manufacturing","Smart Industry","Predictive Maintenance","Interpretable Machine Learning","Autoencoder","Anomaly Discriminator"],"title":"Using an autoencoder in the design of an anomaly detector for smart manufacturing","type":"publication"},{"authors":[],"categories":null,"content":"","date":1582023600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582023600,"objectID":"bc57f30b003b21fbab073e7a0136a896","permalink":"https://gmanco.github.io/talk/isi-feb20/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/isi-feb20/","section":"talk","summary":"I discuss some issues and solutions in devising generative models for marked temporal poin processes.","tags":["Point Processes","Generative models"],"title":"Adversarial Games for generative modeling of Temporally-Marked Event Sequences","type":"talk"},{"authors":null,"categories":null,"content":"In what follows I'll try to explain my basic understanding and interepretation of the semi-supervised framework based on Variational Autoencoders, as described in [1]. I shall assume a vector notation where bold symbols $\\mathbf{a}$ represent vectors, whose $j$-th component can be represented as $a_j$.\nThe starting point of the framework is to consider a dataset \\(D = S \\cup U\\), where:\n \\(S = \\{(\\mathbf{x}_1, \\mathbf{y}_1), \\ldots, (\\mathbf{x}_n, \\mathbf{y}_n)\\}\\),\n \\(U = \\{\\mathbf{x}_{n+1}, \\ldots, \\mathbf{x}_{n+m}\\}\\),  with \\(\\mathbf{x}_i \\in \\mathbb{R}^N\\) and \\(\\mathbf{y}_i \\in \\{0,1\\}^C\\) represents a one-hot encoding of a class in \\(\\{1, \\ldots, C\\}\\).\nThe basic assumption of variational autoencoders is that data is generated according to a density function \\(p_\\theta(\\mathbf{x}| \\mathbf{z})\\), where \\(\\mathbf{z}\\in \\mathbb{R}^K\\) is a latent variables governing the distribution of \\(\\mathbf{x}\\). \\(\\theta\\) represents a model parameter. The above density function can be modeled through a Neural network: thus \\(\\theta\\) represents all the network weights. An example PyTorch snippet, where the density is be modeled as a softmax over a simple linear layer, is illustrated below.\nimport torch import torch.nn as nn class Decoder(nn.Module): def __init__(self, latent_size,num_classes,out_size): super(Decoder, self).__init__() self.linear_layer = nn.Linear(latent_size + num_classes, out_size) nn.init.xavier_normal_(self.layer.weight) self.activation = nn.Sigmoid(dim=-1) def forward(self, z): return self.activation(self.linear_layer(z))  Here, we are assuming $\\mathbf{x}$ binary and consequently the reconstruction exploits a bernoullian distribution for each feature.\nLet's see how the generative framework can model the likelihood of the data and help us develop a semi-supervised classifier.\nUnsupervised examples First, let us consider \\(\\mathbf{x}\\in U\\). When \\(\\mathbf{y}\\) is unknown, we can consider it as a latent variable as well. Both \\(\\mathbf{y}\\) and \\(\\mathbf{z}\\) assume a prior distribution, given by\n\\[\\begin{split} \\mathbf{z} \\sim \u0026 \\mathcal{N}(\\mathbf{0},I_K)\\\\ \\mathbf{y} \\sim \u0026 \\mathit{Cat}(\\boldsymbol\\pi) \\end{split}\\]\nHere, \\(\\boldsymbol\\pi\\) is a prior multinomial distribution over \\(\\{1, \\ldots, C\\}\\).\nIn such a case, we can extend the generative setting where data samples $\\mathbf{x}$ are assumed to be generated by the conditional \\(p_\\theta(\\mathbf{x}| \\mathbf{z},\\mathbf{y})\\) through the relationship\n\\[ \\begin{equation}\\label{average}\\tag{1} p(\\mathbf{x}) = \\int p_\\theta(\\mathbf{x}| \\mathbf{z}, \\mathbf{y}) p(\\mathbf{z})p(\\mathbf{y}) \\mathrm{d} \\mathbf{z} \\mathrm{d} \\mathbf{y} \\end{equation} \\]\nIn principle, the \\(\\theta\\) parameter can be chosen to maximize the evidence on \\(D\\), i.e. by optimizing \\(\\log p(\\mathbf{x})\\). However, this approach is not feasible because it requires averaging over all possible \\(\\mathbf{z}\\) pairs. We can approximate the likelihood by sampling a subset of $\\mathbf{z}$ latent data points and then averaging over them. Again, this workaround exhibits the drawback that pure random sampling is exposed to high variance. The idea of Variational Autoencoders is to \u0026quot;guide\u0026quot; the sampling by exploiting the evidence: instead of freely choosing $\\mathbf{z},\\mathbf{y}$, we build a sampler \\(q_\\phi(\\mathbf{z},\\mathbf{y}|\\mathbf{x})\\) that tunes the probability of \\(\\mathbf{z},\\mathbf{y}\\) according to $\\mathbf{x}$. In practice, $q_\\phi$ encodes the information regarding \\(\\mathbf{x}\\) into the most probable \\(\\mathbf{z},\\mathbf{y}\\) latent variables.\nWe can factorize the decoder as \\(q_\\phi(\\mathbf{z},\\mathbf{y}| \\mathbf{x}) = q_\\varphi(\\mathbf{z}|\\mathbf{x},\\mathbf{y})q_\\vartheta(\\mathbf{y}|\\mathbf{x})\\), where\n\\[\\begin{split} q_\\varphi(\\mathbf{z}|\\mathbf{x},\\mathbf{y}) \\equiv \u0026 \\mathcal{N}(\\mathbf{z}| \\boldsymbol\\mu_\\varphi(\\mathbf{x},\\mathbf{y}), \\boldsymbol\\sigma_\\varphi(\\mathbf{x},\\mathbf{y})\\cdot I_K)\\\\ q_\\vartheta(\\mathbf{y}|\\mathbf{x}) \\equiv \u0026 \\mathit{Cat}(\\mathbf{y}|\\boldsymbol\\pi_\\vartheta(\\mathbf{x})), \\end{split}\\]\nHere, the parameters \\(\\boldsymbol\\mu_\\varphi(\\mathbf{x},\\mathbf{y}), \\boldsymbol\\sigma_\\varphi(\\mathbf{x},\\mathbf{y})\\) and \\(\\boldsymbol\\pi_\\vartheta(\\mathbf{x})\\) represent neural functions parameterized by $\\varphi$ and $\\vartheta$, respectively. Again, a PyTorch snippet is given below, where the two encoders are exemplified. Concerning \\(q_\\varphi(\\mathbf{z}|\\mathbf{x}, \\mathbf{y})\\), we have:\nclass Encoder_z(nn.Module): def __init__(self, input_size,latent_size): super(Decoder, self).__init__() self.latent_size = latent_size self.linear_layer = nn.Linear(input_size, 2*latent_size) nn.init.xavier_normal_(self.linear_layer.weight) def _sample_latent(self, mu_q, logvar_q): var_q = torch.exp(logvar_q) epsilon = torch.randn(var_q.size(),requires_grad=False).to(var_q.device) return mu_q + epsilon*var_q def forward(self, x, y): input = torch.cat([x,y],dim=-1) temp_out = self.linear_layer(input) mu_q = temp_out[:, :self.latent_size] logvar_q = temp_out[:, self.latent_size:] z = self._sample_latent(mu_q, logvar_q) return z, mu_q, logvar_q ​```  The computation within this class is a variable \\(\\mathbf{z}\\sim q_\\varphi(\\cdot |\\mathbf{x},\\mathbf{y})\\), as well as the parameters of the variational (gaussian) distribution \\(\\boldsymbol\\mu\\) and \\(\\boldsymbol\\sigma\\). Here, we are exploiting the reparameterization trick: given a variable \\(\\boldsymbol\\epsilon \\sim \\mathcal{N}(\\mathbf{0},I_K)\\), the transformation \\(z = \\mu + \\epsilon \\cdot \\sigma\\) guarantees that \\(\\mathbf{z}\\sim \\mathcal{N}(\\boldsymbol\\mu, \\boldsymbol\\sigma)\\) and at the same time it preserves the backpropagation of the gradient, since \\( \\frac{\\partial \\mathbf{z}}{\\partial w} = \\frac{\\partial \\boldsymbol\\mu}{\\partial w} + \\boldsymbol\\epsilon \\cdot \\frac{\\partial \\boldsymbol\\sigma}{\\partial w} \\) and both \\(\\boldsymbol\\mu\\) and \\(\\boldsymbol\\sigma\\) are deterministically computed as shown above.\nSimilarly, \\(q_\\vartheta(\\mathbf{y}|\\mathbf{x})\\) is exemplified by the following snippet:\nclass Classifier(nn.Module): def __init__(self, input_size,num_classes): super(Decoder, self).__init__() self.linear_layer = nn.Linear(input_size, 2*latent_size) nn.init.xavier_normal_(self.layer.weight) self.softmax = nn.Softmax(dim=-1) def forward(self, x): return self.softmax(self.linear_layer(x))  Notice that, differently from the previous case, within this class we directly output a probability distribution \\(q_\\vartheta(\\mathbf{y}|\\mathbf{x})\\), rather than a sample \\(\\mathbf{y} \\sim q_\\vartheta(\\cdot|\\mathbf{x})\\). The reason for this choice is that no reparameterization trick is possible for a discrete distribution that preserves backpropagation. However, this does not prevent us from averaging over all possible samples, as we shall see later.\nWhat is the relationship between the encoders and the decoder? We can observe that\n\\( \\begin{split} \\log p(\\mathbf{x}) \\geq \u0026 \\mathbb{E}_{q_\\phi(\\mathbf{z},\\mathbf{y}| \\mathbf{x})}\\left[\\log p_\\theta(\\mathbf{x}| \\mathbf{z}) + \\log p(\\mathbf{z}) + \\log p(\\mathbf{y}) - \\log q_\\phi(\\mathbf{z},\\mathbf{y}| \\mathbf{x})\\right] \\\\ = \u0026 \\sum_\\mathbf{y} \\mathbb{E}_{q_\\varphi(\\mathbf{z}| \\mathbf{x},\\mathbf{y})}\\Bigg[ q_\\vartheta(\\mathbf{y}| \\mathbf{x})\\bigg(\\log p_\\theta(\\mathbf{x}| \\mathbf{z}) + \\log p(\\mathbf{y}) - \\log q_\\vartheta(\\mathbf{y}| \\mathbf{x})\\bigg) \\\\ \u0026 \\qquad \\qquad + \\log p(\\mathbf{z}) - \\log q_\\varphi(\\mathbf{z}| \\mathbf{x},\\mathbf{y})\\Bigg] \\end{split} \\) We call the right-hand side of the equation the Evidence Lower Bound (ELBO). It turns out that, optimizing this equation with respect to \\(\\phi, \\theta\\) corresponds to optimizing \\(\\log p(\\mathbf{x})\\) as well. Thus, we can specify the loss \\(\\ell(\\mathit{x})\\) as the negative of the ELBO and exploit a gradient-based optimization strategy. The main difference with respect to directly optimizing eq. (\\(\\ref{average}\\)) is that the ELBO is tractable. In fact, we can rewrite it as\n\\(\\begin{split} \\ell(\\mathbf{x})= \u0026 - \\sum_\\mathbf{y} \\mathbb{E}_{\\boldsymbol\\epsilon\\sim \\mathcal{N}(\\mathbf{0},I_K)}\\Bigg[ q_\\vartheta(\\mathbf{y}| \\mathbf{x})\\bigg(\\log p_\\theta(\\mathbf{x}| \\mathbf{z}(\\boldsymbol\\epsilon, \\mathbf{x},\\mathbf{y})) + \\log p(\\mathbf{y}) - \\log q_\\vartheta(\\mathbf{y}| \\mathbf{x})\\bigg) \\\\ \u0026 \\qquad \\qquad + \\log p(\\mathbf{z}(\\boldsymbol\\epsilon, \\mathbf{x},\\mathbf{y})) - \\log q_\\varphi(\\mathbf{z}(\\boldsymbol\\epsilon, \\mathbf{x},\\mathbf{y})| \\mathbf{x},\\mathbf{y})\\Bigg] \\end{split}\\) where \\(\\mathbf{z}(\\boldsymbol\\epsilon, \\mathbf{x},\\mathbf{y}) = \\boldsymbol\\mu_\\varphi(\\mathbf{x},\\mathbf{y}) + \\boldsymbol\\epsilon \\cdot \\sigma_\\varphi(\\mathbf{x},\\mathbf{y})\\) represents the \\(\\mathbf{z}\\) component in the output of Decoder_z and \\(q_{\\vartheta}(\\mathbf{y}| \\mathbf{x})\\) represents the output of Classifier.\nBy analysing the above equation we can observe the following:\n Since \\(q_\\vartheta(\\mathbf{y}| \\mathbf{x}) = \\prod_{j=1}^C \\pi_{\\vartheta,j}(\\mathbf{x})^{y_j}\\) and \\(\\mathbf{y}\\) ranges over all possible classes, we can simplify the first part of the right-hand side of the equation with \\(\\sum_{j = 1}^C \\pi_{\\vartheta,j}(\\mathbf{x})\\bigg(p_\\theta(\\mathbf{x}| \\mathbf{z}(\\epsilon,\\mathbf{x},\\mathbf{y}), \\mathbf{e}_j) + \\log \\pi_j - \\log \\pi_{\\vartheta,j}(\\mathbf{x})\\bigg)\\), where \\(\\mathbf{e}_j\\) is the vector of all zeros except for position \\(j\\) and \\(\\pi_{\\vartheta,j}(\\mathbf{x})\\) is the \\(j\\)-th component of \\(\\pi_{\\vartheta}(\\mathbf{x})\\).\n Further, by exploiting the definitions, \\(\\mathbb{E}_{\\boldsymbol\\epsilon\\sim \\mathcal{N}(\\mathbf{0},I_K)}\\left[\\log p(\\mathbf{z}(\\boldsymbol\\epsilon, \\mathbf{x},\\mathbf{y})) - \\log q_\\varphi(\\mathbf{z}(\\boldsymbol\\epsilon, \\mathbf{x},\\mathbf{y})| \\mathbf{x},\\mathbf{y})\\right] = \\sum_{k} \\Bigg(\\log \\sigma_{\\varphi,k}(\\mathbf{x},\\mathbf{y}) + 1 - \\sigma_{\\varphi,k}(\\mathbf{x},\\mathbf{y}) - \\boldsymbol\\mu_{\\varphi,k}(\\mathbf{x},\\mathbf{y})^2\\Bigg)\\) and we see that the only source of nondeterminism is given by the component that computes the log-likelihood.\n  To summarize, the loss for an element \\(\\mathbf{x} \\in U\\) can be fully specified as follows:\n\\[\\begin{split} \\ell(\\mathbf{x})= \u0026 \\sum_{j = 1}^C \\pi_{\\vartheta,j}(\\mathbf{x})\\left(\\log \\pi_{\\vartheta,j}(\\mathbf{x}) - \\log \\pi_j \\right) \\\\ \u0026 - \\mathbb{E}_{\\boldsymbol\\epsilon\\sim \\mathcal{N(\\mathbf{0},I_K)}}\\left[\\sum_{j = 1}^C \\pi_{\\vartheta,j}(\\mathbf{x})p_\\theta(\\mathbf{x}| \\mathbf{z}(\\boldsymbol\\epsilon,\\mathbf{x},\\mathbf{e}_j), \\mathbf{e}_j)\\right]\\\\ \u0026 - \\sum_{j = 1}^C \\sum_{k} \\Bigg(\\log \\sigma_{\\varphi,k}(\\mathbf{x},\\mathbf{e}_j) + 1 - \\sigma_{\\varphi,k}(\\mathbf{x},\\mathbf{e}_j) - \\mu_{\\varphi,k}(\\mathbf{x},\\mathbf{e}_j)^2\\Bigg) \\end{split}\\]\nThe code snippet illustrating \\(\\ell(\\mathbf{x})\\) in PyTorch is the following.\ndef unsupervised_loss(x,encoder,decoder,classifier,num_classes,y_prior=1): y_q = classifier(x) kld_cat = torch.mean(torch.sum(y_q*(torch.exp(y_q) - torch.log(y_prior)),-1),-1) kld_norm = 0 e = torch.zeros(y_q.size()).to(x.device) prob_e = [] for j in range(num_classes): e[:,j] = 1. z, mu_q, logvar_q = encoder(x,e) kld_norm += torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1) prob_e.append(decoder(z)) e[:,j] = 0. kld_norm = torch.mean(kld_norm, -1) prob_e = torch.floatTensor(log_prob_e) prob_x = torch.matmul(llk_e,y_q).squeeze() loss = nn.BCELoss() llk = loss(prob_x,x) return llk + kld_cat + kld_norm  Here, since Decoder provides a probability distribution, the loss is the negative log likelihood. Again, we are assuming $\\mathbf{x}$ binary and the underlying probability is bernoullian on each feature.\nSupervised examples The case \\((\\mathbf{x},\\mathbf{y})\\in S\\) rensembles the unsupervised case, but with a major difference. For the labelled case, the joint probability \\(p(\\mathbf{x},\\mathbf{y},\\mathbf{z})\\) is decomposed as \\(p_\\theta(\\mathbf{x},\\mathbf{y},\\mathbf{z}) = q_{\\vartheta}(\\mathbf{y}|\\mathbf{x})p_\\theta(\\mathbf{x}|\\mathbf{z})p(\\mathbf{z})\\). In practice, we consider here a discriminative setting where the Classifier component as a part of the decoder. This is different from the unsupervised case, where \\(\\mathbf{y}\\) was considered a latent variable which encoded latent information from $\\mathbf{x}$ in a generative setting.\nAs a consequence, the joint likelihood can be approximated as\n\\[\\begin{split} \\log p(\\mathbf{x},\\mathbf{y}) \\geq \u0026 \\mathbb{E}_{q_\\varphi(\\mathbf{z}| \\mathbf{x},\\mathbf{y})}\\Bigg[\\log p_\\theta(\\mathbf{x}| \\mathbf{z}) + \\log q_\\vartheta(\\mathbf{y}|\\mathbf{x}) + \\log p(\\mathbf{z}) - \\log q_\\varphi(\\mathbf{z}| \\mathbf{x},\\mathbf{y})\\Bigg] \\end{split}\\]\nBy rearranging the formulas, we obtain the loss term for the supervised case:\n\\[\\begin{split}\\ell(\\mathbf{x},\\mathbf{y}) = \u0026 \\mathbb{E}_{\\boldsymbol\\epsilon\\sim \\mathcal{N}(0,1)}\\Bigg[\\log p_\\theta(\\mathbf{x}| \\mathbf{z}(\\boldsymbol\\epsilon,\\mathbf{x}, \\mathbf{y}))\\Bigg] \\\\ \u0026 + \\sum_{j=1}^C y_j \\log \\pi_{\\vartheta,j}(\\mathbf{x}) \\\\\u0026 + \\sum_{k} \\Bigg(\\log \\sigma_{\\varphi,k}(\\mathbf{x},\\mathbf{y}) + 1 - \\sigma_{\\varphi,k}(\\mathbf{x},\\mathbf{y}) - \\mu_{\\varphi,k}(\\mathbf{x},\\mathbf{y})^2\\Bigg)\\end{split}\\]\nThe corresponding example implementation:\ndef supervised_loss(x,y,encoder,decoder,classifier): z, mu_q, logvar_q = encoder(x,y) kld_norm = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1),-1) prob_x = decoder(x) loss = nn.BCELoss() llk = loss(prob_x,x) y_q = classifier(x) loss = CrossEntropyLoss(dim=-1) llk_cat = loss(y_q,y) return llk + llk_cat + kld_norm  Other interpretations for the supervised case are possible: see, e.g. the treatment in Brian Keng's blog. However, I feel that separating the supervised and the unsupervised case and arranging the derivations accordingly is more intuitive.\nWrapping up We can finally combine all the above and devise a model for semi-supervised training:\nclass SSVAE(nn.Module): def __init__(self,input_size,num_classes,latent_size, y_prior = 1): self.input_size = input_size self.num_classes = num_classes self.latent_size = latent_size self.y_prior = y_prior self.encoder = Encoder(input_size,num_classes,latent_size) self.decoder = Decoder(latent_size,input_size) self.classifier = Classifier(input_size, num_classes) llk_loss = nn.BCELoss() cat_loss = nn.CrossEntropyLoss() def unsupervised_loss(self, x): y_q = self.classifier(x) kld_cat = torch.mean(torch.sum(y_q*(torch.log(y_q) - torch.log(self.y_prior)),-1),-1) kld_norm = 0 e = torch.zeros(y_q.size()).to(x.device) prob_e = [] for j in range(self.num_classes): e[:,j] = 1. z, mu_q, logvar_q = self.encoder(x,e) kld_norm += torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1) prob_e.append(self.decoder(z)) e[:,j] = 0. kld_norm = torch.mean(kld_norm, -1)) prob_e = torch.floatTensor(log_prob_e) prob_x = torch.matmul(llk_e,y_q).squeeze() llk = llk_loss(prob_x,x) return llk + kld_cat + kld_norm def supervised_loss(self,x,y): z, mu_q, logvar_q = self.encoder(x,y) kld_norm = torch.mean(torch.sum(0.5 * (-logvar_q + torch.exp(logvar_q) + mu_q**2 - 1),-1) prob_x = self.decoder(x) llk = loss(prob_x,x) y_q = self.classifier(x) llk_cat = cat_loss(y_q,y) return llk + llk_cat + kld_norm def forward(self, x, y = None, train = True) if not train: return self.classifier(x) else: if y is not None: loss = self.supervised_loss(x,y) else loss = self.unsupervised_loss(x) return loss  We can observe that the model can be called in two modes: either in train mode or not. For the latter, it acts as a classifier and produces the class probabilities. In the training mode, on the other side, it computes either the supervised or the unsupervised, loss based on whether the data is labelled or not. The training procedure is quite straightforward as it just requires a data_loader capable of ranging over \\(D\\):\ndef train(data_loader,input_size, num_classes, latent_size, y_priors): model = SSVAE(input_size,num_classes, latent_size) optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001) for batch_idx,(x,y) in enumerate(data_loader): optimizer.zero_grad() loss = model(x,y) loss.backward() optimizer.step()  References [1] Diederik P. Kingma, Danilo J. Rezende, Shakir Mohamed, Max Welling. Semi-supervised Learning with Deep Generative Models. Advances in Neural Information Processing Systems 27 (NIPS 2014), Montreal\n","date":1568131809,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568131809,"objectID":"aefb5630cf18e8eeb5c4a75d1cc30f31","permalink":"https://gmanco.github.io/post/on-semisupervised-vae/","publishdate":"2019-09-10T18:10:09+02:00","relpermalink":"/post/on-semisupervised-vae/","section":"post","summary":"In what follows I'll try to explain my basic understanding and interepretation of the semi-supervised framework based on Variational Autoencoders, as described in [1]. I shall assume a vector notation where bold symbols $\\mathbf{a}$ represent vectors, whose $j$-th component can be represented as $a_j$.\nThe starting point of the framework is to consider a dataset \\(D = S \\cup U\\), where:\n \\(S = \\{(\\mathbf{x}_1, \\mathbf{y}_1), \\ldots, (\\mathbf{x}_n, \\mathbf{y}_n)\\}\\),\n \\(U = \\{\\mathbf{x}_{n+1}, \\ldots, \\mathbf{x}_{n+m}\\}\\),  with \\(\\mathbf{x}_i \\in \\mathbb{R}^N\\) and \\(\\mathbf{y}_i \\in \\{0,1\\}^C\\) represents a one-hot encoding of a class in \\(\\{1, \\ldots, C\\}\\).","tags":["Variational Autoencoders","Generative Models","Semi-Supervised Learning"],"title":"Some notes on the Semi-Supervised Learning of Variational Autoencoders","type":"post"},{"authors":[],"categories":[],"content":" Welcome to Slides Academic\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides  Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E  Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = \\;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \nA fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears  Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view   Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links   night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links  Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://gmanco.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Giuseppe Manco","Ettore Ritacco","Nicola Barbieri"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"92fadd39e26ac4c18e4e877cb6769a15","permalink":"https://gmanco.github.io/publication/manco-2019/","publishdate":"2019-09-07T09:18:44.877085Z","relpermalink":"/publication/manco-2019/","section":"publication","summary":"In this paper we propose a survival factorization framework that models information cascades by tying together social influence patterns, topical structure and temporal dynamics. This is achieved through the introduction of a latent space which encodes: (a) the relevance of an information cascade on a topic; (b) the topical authoritativeness and the susceptibility of each individual involved in the information cascade, and (c) temporal topical patterns. By exploiting the cumulative properties of the survival function and of the likelihood of the model on a given adoption log, which records the observed activation times of users and side-information for each cascade, we show that the inference phase is linear in the number of users and in the number of adoptions. The evaluation on both synthetic and real-world data shows the effectiveness of the model in detecting the interplay between topics and social influence patterns, which ultimately provides high accuracy in predicting users activation times.","tags":["Social Influence","Information Diffusion","Social Network Analysis","Community Detection","Temporal Point Processes","Embedding","Generative Models"],"title":"A Factorization Approach for Survival Analysis on Diffusion Networks","type":"publication"},{"authors":["Noveen Sachdeva","Giuseppe Manco","Ettore Ritacco","Vikram Pudi"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"36136770e8928466cf6d4291ccfd4ad3","permalink":"https://gmanco.github.io/publication/sachdeva-2019/","publishdate":"2019-09-07T09:18:44.874439Z","relpermalink":"/publication/sachdeva-2019/","section":"publication","summary":"Variational autoencoders were proven successful in domains such as computer vision and speech processing. Their adoption for modeling user preferences is still unexplored, although recently it is starting to gain attention in the current literature. In this work, we propose a model which extends variational autoencoders by exploiting the rich information present in the past preference history. We introduce a recurrent version of the VAE, where instead of passing a subset of the whole history regardless of temporal dependencies, we rather pass the consumption sequence subset through a recurrent neural network. At each time-step of the RNN, the sequence is fed through a series of fully-connected layers, the output of which models the probability distribution of the most likely future preferences. We show that handling temporal information is crucial for improving the accuracy of the VAE: In fact, our model beats the current state-of-the-art by valuable margins because of its ability to capture temporal dependencies among the user-consumption sequence using the recurrent encoder still keeping the fundamentals of variational autoencoders intact.","tags":["Variational Autoencoders","Recurrent Networks","Sequence modeling","Collaborative Filtering","Deep Learning","Recommender Systems","Generative Models"],"title":"Sequential Variational Autoencoders for Collaborative Filtering","type":"publication"},{"authors":["Giuseppe Manco","Giuseppe Pirrò","Ettore Ritacco"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"9503dd9f9cd748dd797d456d374e6530","permalink":"https://gmanco.github.io/publication/manco-2018/","publishdate":"2019-09-07T09:18:44.891002Z","relpermalink":"/publication/manco-2018/","section":"publication","summary":"We tackle the problem of predict whether a target user (or group of users) will be active within an event stream before a time horizon. Our solution, called PATH, leverages recurrent neural networks to learn an embedding of the past events. The embedding allows to capture influence and susceptibility between users and places closer (the representation of) users that frequently get active in different event streams within a small time interval. We conduct an experimental evaluation on real world data and compare our approach with related work.","tags":["Social Influence","Information Diffusion","Deep Learning","Recurrent Networks","Temporal Point Processes"],"title":"Predicting Temporal Activation Patterns via Recurrent Neural Networks","type":"publication"},{"authors":["Giuseppe Manco","Ettore Ritacco","Pasquale Rullo","Lorenzo Gallucci","Will Astill","Dianne Kimber","Marco Antonelli"],"categories":null,"content":"","date":1509494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1509494400,"objectID":"24d06858f9d77e97fe9f38cf5247a9fc","permalink":"https://gmanco.github.io/publication/manco-2017/","publishdate":"2019-09-07T09:18:44.893116Z","relpermalink":"/publication/manco-2017/","section":"publication","summary":"Fault prediction is an important topic for the industry as, by providing effective methods for predictive maintenance, allows companies to perform important time and cost savings. In this paper we describe an application developed to predict and explain door failures on metro trains. To this end, the aim was twofold: first, devising prediction techniques capable of early detecting door failures from diagnostic data; second, describing failures in terms of properties distinguishing them from normal behavior. Data pre-processing was a complex task aimed at overcoming a number of issues with the dataset, like size, sparsity, bias, burst effect and trust. Since failure premonitory signals did not share common patterns, but were only characterized as non-normal device signals, fault prediction was performed by using outlier detection. Fault explanation was finally achieved by exhibiting device features showing abnormal values. An experimental evaluation was performed to assess the quality of the proposed approach. Results show that high-degree outliers are effective indicators of incipient failures. Also, explanation in terms of abnormal feature values (responsible for outlierness) seems to be quite expressive.There are some aspects in the proposed approach that deserve particular attention. We introduce a general framework for the failure detection problem based on an abstract model of diagnostic data, along with a formal problem statement. They both provide the basis for the definition of an effective data pre-processing technique where the behavior of a device, in a given time frame, is summarized through a number of suitable statistics. This approach strongly mitigates the issues related to data errors/noise, thus enabling to perform an effective outlier detection. All this, in our view, provides the grounds of a general methodology for advanced prognostic systems.","tags":["Fault Detection","Anomaly Detection","Outlier Explanation","Big Data","Sensor Data","Predictive Maintenance"],"title":"Fault detection and explanation through big data analysis on sensor streams","type":"publication"},{"authors":["Giuseppe Manco","Giuseppe Pirrò"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f5981592235ff919d25c4517486177cc","permalink":"https://gmanco.github.io/publication/manco-2017-a/","publishdate":"2019-09-07T09:18:44.896224Z","relpermalink":"/publication/manco-2017-a/","section":"publication","summary":"The soaring amount of data coming from a variety of sources including social networks and mobile devices opens up new perspectives while at the same time posing new challenges. On one hand, AI-systems like Neural Networks paved the way toward new applications ranging from self-driving cars to text understanding. On the other hand, the management and analysis of data that fed these applications raises concerns about the privacy of data contributors. One robust (from the mathematical point of view) privacy definition is that of Differential Privacy (DP). The peculiarity of DP-based algorithms is that they do not work on anonymized versions of the data; they add a calibrated amount of noise before releasing the results, instead. The goals of this paper are: to give an overview on recent research results marrying DP and neural networks; to present a blueprint for differentially private neural networks; and, to discuss our findings and point out new research challenges.","tags":["Deep Learning","Differential Privacy"],"title":"Differential Privacy and Neural Networks: A Preliminary Analysis","type":"publication"},{"authors":["Nicola Barbieri","Giuseppe Manco","Ettore Ritacco"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"a6bab7156443905fc3c087016470c7d0","permalink":"https://gmanco.github.io/publication/barbieri-2017/","publishdate":"2019-09-07T09:18:44.905412Z","relpermalink":"/publication/barbieri-2017/","section":"publication","summary":"","tags":["Social Influence","Information Diffusion","Social Network Analysis","Community Detection","Temporal Point Processes","Embedding","Generative Models"],"title":"Survival Factorization on Diffusion Networks","type":"publication"},{"authors":["Nicola Barbieri","Francesco Bonchi","Giuseppe Manco"],"categories":null,"content":"","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"0f3611d5af8ec1d15892474902e569af","permalink":"https://gmanco.github.io/publication/barbieri-2016/","publishdate":"2019-09-07T09:18:44.894266Z","relpermalink":"/publication/barbieri-2016/","section":"publication","summary":"We study the problem of detecting social communities when the social graph is not available but instead we have access to a log of user activity, that is, a dataset of tuples (u, i, t) recording the fact that user u “adopted” item i at time t. We propose a stochastic framework that assumes that the adoption of items is governed by an underlying diffusion process over the unobserved social network and that such a diffusion model is based on community-level influence. That is, we aim at modeling communities through the lenses of social contagion. By fitting the model parameters to the user activity log, we learn the community membership and the level of influence of each user in each community. The general framework is instantiated with two different diffusion models, one with discrete time and one with continuous time, and we show that the computational complexity of both approaches is linear in the number of users and in the size of the propagation log. Experiments on synthetic data with planted community structure show that our methods outperform non-trivial baselines. The effectiveness of the proposed techniques is further validated on real-word data, on which our methods are able to detect high-quality communities.","tags":["Social Influence","Information Diffusion","Social Network Analysis","Community Detection","Temporal Point Processes","Generative Models"],"title":"Efficient Methods for Influence-Based Network-Oblivious Community Detection","type":"publication"},{"authors":["Giuseppe Manco","Pasquale Rullo","Lorenzo Gallucci","Mirko Paturzo"],"categories":null,"content":"","date":1475280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475280000,"objectID":"0d0949a67019a4e700b48b6519860c8d","permalink":"https://gmanco.github.io/publication/manco-2016/","publishdate":"2019-09-07T09:18:44.897728Z","relpermalink":"/publication/manco-2016/","section":"publication","summary":"A Knowledge Discovery (KD) process is a complex inter-disciplinary task, where different types of techniques coexist and cooperate for the purpose of extracting useful knowledge from large amounts of data. So, it is desirable having a unifying environment, built on a formal basis, where to design and perform the overall process. In this paper we propose a general framework which formalizes a KD process as an algebraic expression, that is, as a composition of operators representing elementary operations on two worlds: the data and the model worlds. Then, we describe a KD platform, named Rialto, based on such a framework. In particular, we provide the design principles of the underlying architecture, highlight the basic features, and provide a number of experimental results aimed at assessing the effectiveness of the design choices.","tags":["Knowledge Discovery Process","Data Mining","Business Analytics Platforms"],"title":"Rialto: A Knowledge Discovery suite for data analysis","type":"publication"},{"authors":["Shirley Coleman","Rainer Göb","Giuseppe Manco","Antonio Pievatolo","Xavier Tort-Martorell","Marco Seabra Reis"],"categories":null,"content":"","date":1462060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462060800,"objectID":"fe57696a5f66285140db50393e766a3e","permalink":"https://gmanco.github.io/publication/coleman-2016/","publishdate":"2019-09-07T09:18:44.899375Z","relpermalink":"/publication/coleman-2016/","section":"publication","summary":"Big data is big news, and large companies in all sectors are making significant advances in their customer relations, product selection and development and consequent profitability through using this valuable commodity. Small and medium enterprises (SMEs) have proved themselves to be slow adopters of the new technology of big data analytics and are in danger of being left behind. In Europe, SMEs are a vital part of the economy, and the challenges they encounter need to be addressed as a matter of urgency. This paper identifies barriers to SME uptake of big data analytics and recognises their complex challenge to all stakeholders, including national and international policy makers, IT, business management and data science communities.  The paper proposes a big data maturity model for SMEs as a first step towards an SME roadmap to data analytics. It considers the ‘state‐of‐the‐art’ of IT with respect to usability and usefulness for SMEs and discusses how SMEs can overcome the barriers preventing them from adopting existing solutions. The paper then considers management perspectives and the role of maturity models in enhancing and structuring the adoption of data analytics in an organisation. The history of total quality management is reviewed to inform the core aspects of implanting a new paradigm. The paper concludes with recommendations to help SMEs develop their big data capability and enable them to continue as the engines of European industrial and business success. ","tags":["Big Data"],"title":"How Can SMEs Benefit from Big Data? Challenges and a Path Forward","type":"publication"},{"authors":["Fabrizio Angiulli","Fabio Fassetti","Giuseppe Manco","Luigi Palopoli"],"categories":null,"content":"","date":1456790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456790400,"objectID":"012d7da8acfb1ddeec504c89e982c523","permalink":"https://gmanco.github.io/publication/angiulli-2016/","publishdate":"2019-09-07T09:18:44.892117Z","relpermalink":"/publication/angiulli-2016/","section":"publication","summary":"The outlying property detection problem (OPDP) is the problem of discovering the properties distinguishing a given object, known in advance to be an outlier in a database, from the other database objects. This problem has been recently analyzed focusing on categorical attributes only. However, numerical attributes are very relevant and widely used in databases. Therefore, in this paper, we analyze the OPDP within a context where also numerical attributes are taken into account, which represents a relevant case left open in the literature. As major contributions, we present an efficient parameter-free algorithm to compute the measure of object exceptionality we introduce, and propose a unified framework for mining exceptional properties in the presence of both categorical and numerical attributes.","tags":["Anomaly Detection","Explanation","Outlier Explanation","Probabilistic Modeling","Density Estimation"],"title":"Outlying property detection with numerical attributes","type":"publication"},{"authors":["Nicola Barbieri","Giuseppe Manco","Ettore Ritacco"],"categories":null,"content":"","date":1398902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1398902400,"objectID":"39b06ab51e7c95d4aa1d566867c653c6","permalink":"https://gmanco.github.io/publication/barbieri-2014/","publishdate":"2019-09-07T09:18:44.900808Z","relpermalink":"/publication/barbieri-2014/","section":"publication","summary":"The importance of accurate recommender systems has been widely recognized by academia and industry, and recommendation is rapidly becoming one of the most successful applications of data mining and machine learning. Understanding and predicting the choices and preferences of users is a challenging task: real-world scenarios involve users behaving in complex situations, where prior beliefs, specific tendencies, and reciprocal influences jointly contribute to determining the preferences of users toward huge amounts of information, services, and products. Probabilistic modeling represents a robust formal mathematical framework to model these assumptions and study their effects in the recommendation process.  This book starts with a brief summary of the recommendation problem and its challenges and a review of some widely used techniques Next, we introduce and discuss probabilistic approaches for modeling preference data. We focus our attention on methods based on latent factors, such as mixture models, probabilistic matrix factorization, and topic models, for explicit and implicit preference data. These methods represent a significant advance in the research and technology of recommendation. The resulting models allow us to identify complex patterns in preference data, which can be exploited to predict future purchases effectively.  The extreme sparsity of preference data poses serious challenges to the modeling of user preferences, especially in the cases where few observations are available. Bayesian inference techniques elegantly address the need for regularization, and their integration with latent factor modeling helps to boost the performances of the basic techniques.  We summarize the strengths and weakness of several approaches by considering two different but related evaluation perspectives, namely, rating prediction and recommendation accuracy. Furthermore, we describe how probabilistic methods based on latent factors enable the exploitation of preference patterns in novel applications beyond rating prediction or recommendation accuracy.  We finally discuss the application of probabilistic techniques in two additional scenarios, characterized by the availability of side information besides preference data. In summary, the book categorizes the myriad probabilistic approaches to recommendations and provides guidelines for their adoption in real-world situations.","tags":["Generative Models","Matrix Factorization","Topic Models","Recommender Systems","Collaborative Filtering","Social Network Analysis"],"title":"Probabilistic Approaches to Recommendations","type":"publication"},{"authors":["Gianni Costa","Giuseppe Manco","Riccardo Ortale"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"a4abe9e108a1fee568d35153a56168ab","permalink":"https://gmanco.github.io/publication/costa-2014/","publishdate":"2019-09-07T09:18:44.866796Z","relpermalink":"/publication/costa-2014/","section":"publication","summary":"A Bayesian generative model is presented for recommending interesting items and trustworthy users to the targeted users in social rating networks with asymmetric and directed trust relationships. The proposed model is the first unified approach to the combination of the two recommendation tasks. Within the devised model, each user is associated with two latent-factor vectors, i.e., her susceptibility and expertise. Items are also associated with corresponding latent-factor vector representations. The probabilistic factorization of the rating data and trust relationships is exploited to infer user susceptibility and expertise. Statistical social-network modeling is instead used to constrain the trust relationships from a user to another to be governed by their respective susceptibility and expertise. The inherently ambiguous meaning of unobserved trust relationships between users is suitably disambiguated. An intensive comparative experimentation on real-world social rating networks with trust relationships demonstrates the superior predictive performance of the presented model in terms of RMSE and AUC.","tags":["Collaborative Filtering","Matrix Factorization","Social Network Analysis","Recommender Systems","Embedding"],"title":"A Generative Bayesian Model for Item and User Recommendation in Social Rating Networks with Trust Relationships","type":"publication"},{"authors":["Nicola Barbieri","Francesco Bonchi","Giuseppe Manco"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"6bee2fb5d168ceaa8aa7d1de73b84052","permalink":"https://gmanco.github.io/publication/barbieri-2014-a/","publishdate":"2019-09-07T09:18:44.904056Z","relpermalink":"/publication/barbieri-2014-a/","section":"publication","summary":"User recommender systems are a key component in any on-line social networking platform: they help the users growing their network faster, thus driving engagement and loyalty. In this paper we study link prediction with explanations for user recommendation in social networks. For this problem we propose WTFW (\"Who to Follow and Why\"), a stochastic topic model for link prediction over directed and nodes-attributed graphs. Our model not only predicts links, but for each predicted link it decides whether it is a \"topical\" or a \"social\" link, and depending on this decision it produces a different type of explanation. A topical link is recommended between a user interested in a topic and a user authoritative in that topic: the explanation in this case is a set of binary features describing the topic responsible of the link creation. A social link is recommended between users which share a large social neighborhood: in this case the explanation is the set of neighbors which are more likely to be responsible for the link creation. Our experimental assessment on real-world data confirms the accuracy of WTFW in the link prediction and the quality of the associated explanations.","tags":["Social Influence","Information Diffusion","Social Network Analysis","Link Prediction","Generative Models","Topic Modeling"],"title":"Who to follow and why","type":"publication"},{"authors":["Nicola Barbieri","Francesco Bonchi","Giuseppe Manco"],"categories":null,"content":"","date":1385856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1385856000,"objectID":"6ad73003c3dd06decb1ce4b9f0bf7a53","permalink":"https://gmanco.github.io/publication/barbieri-2013-a/","publishdate":"2019-09-07T09:18:44.871284Z","relpermalink":"/publication/barbieri-2013-a/","section":"publication","summary":"How can we detect communities when the social graphs is not available? We tackle this problem by modeling social contagion from a log of user activity, that is a dataset of tuples (u, i, t) recording the fact that user u \"adopted\" item i at time t. This is the only input to our problem. We propose a stochastic framework which assumes that item adoptions are governed by un underlying diffusion process over the unobserved social network, and that such diffusion model is based on community-level influence. By fitting the model parameters to the user activity log, we learn the community membership and the level of influence of each user in each community. This allows to identify for each community the \"key\" users, i.e., the leaders which are most likely to influence the rest of the community to adopt a certain item. The general framework can be instantiated with different diffusion models. In this paper we define two models: the extension to the community level of the classic (discrete time) Independent Cascade model, and a model that focuses on the time delay between adoptions. To the best of our knowledge, this is the first work studying community detection without the network.","tags":["Social Influence","Information Diffusion","Social Network Analysis","Community Detection","Temporal Point Processes","Generative Models"],"title":"Influence-Based Network-Oblivious Community Detection","type":"publication"},{"authors":["Gianni Costa","Giuseppe Manco","Elio Masciari"],"categories":null,"content":"","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"771c53d679bd0df7b61d16f7642f202f","permalink":"https://gmanco.github.io/publication/costa-2013-a/","publishdate":"2019-09-07T09:18:44.902128Z","relpermalink":"/publication/costa-2013-a/","section":"publication","summary":"Nowadays, almost all kind of electronic devices leave traces of their movements (e.g. smartphone, GPS devices and so on). Thus, the huge number of this “tiny” data sources leads to the generation of massive data streams of geo-referenced data. As a matter of fact, the effective analysis of such amounts of data is challenging, since the possibility to extract useful information from this peculiar kind of data is crucial in many application scenarios such as vehicle traffic management, hand-off in cellular networks, supply chain management. Moreover, spatial data streams management poses new challenges both for their proper definition and acquisition, thus making the overall process harder than for classical point data. In particular, we are interested in solving the problem of effective trajectory data streams clustering, that revealed really intriguing as we deal with sequential data that have to be properly managed due to their ordering. We propose a framework that allow data pre-elaboration in order to make the mining step more effective. As for every data mining tool, the experimental evaluation is crucial, thus we performed several tests on real world datasets that confirmed the efficiency and effectiveness of the proposed approach.","tags":["Spatial Data"," Math transforms","Clustering"],"title":"Dealing with trajectory streams by clustering and mathematical transforms","type":"publication"},{"authors":["Nicola Barbieri","Giuseppe Manco","Ettore Ritacco","Marco Carnuccio","Antonio Bevacqua"],"categories":null,"content":"","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"9abcdba862d257d45919745dd7479715","permalink":"https://gmanco.github.io/publication/barbieri-2013-b/","publishdate":"2019-09-07T09:18:44.88836Z","relpermalink":"/publication/barbieri-2013-b/","section":"publication","summary":"Probabilistic topic models are widely used in different contexts to uncover the hidden structure in large text corpora. One of the main (and perhaps strong) assumption of these models is that generative process follows a bag-of-words assumption, i.e. each token is independent from the previous one. We extend the popular Latent Dirichlet Allocation model by exploiting three different conditional Markovian assumptions: (i) the token generation depends on the current topic and on the previous token; (ii) the topic associated with each observation depends on topic associated with the previous one; (iii) the token generation depends on the current and previous topic. For each of these modeling assumptions we present a Gibbs Sampling procedure for parameter estimation. Experimental evaluation over real-word data shows the performance advantages, in terms of recall and precision, of the sequence-modeling approaches.","tags":["Recommender Systems","Collaborative Filtering","Topic Models","Generative Models"],"title":"Probabilistic topic models for sequence data","type":"publication"},{"authors":["Nicola Barbieri","Francesco Bonchi","Giuseppe Manco"],"categories":null,"content":"","date":1364774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364774400,"objectID":"fb695ddcd75bb2c6f9427de70db098e9","permalink":"https://gmanco.github.io/publication/barbieri-2013-c/","publishdate":"2019-09-07T19:16:42.66436Z","relpermalink":"/publication/barbieri-2013-c/","section":"publication","summary":"","tags":["Social Influence","Topic Models","Probabilistic Modeling","Information Diffusion"],"title":"Topic-aware social influence propagation models","type":"publication"},{"authors":["Gianni Costa","Giuseppe Manco","Riccardo Ortale","Ettore Ritacco"],"categories":null,"content":"","date":1362096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362096000,"objectID":"7414e297aff312f9ed9119f3560eb959","permalink":"https://gmanco.github.io/publication/costa-2013/","publishdate":"2019-09-07T09:18:44.883865Z","relpermalink":"/publication/costa-2013/","section":"publication","summary":"Clustering XML documents by structure is the task of grouping them by common structural components. Hitherto, this has been accomplished by looking at the occurrence of one preestablished type of structural components in the structures of the XML documents. However, the a-priori chosen structural components may not be the most appropriate for effective clustering. Moreover, it is likely that the resulting clusters exhibit a certain extent of inner structural inhomogeneity, because of uncaught differences in the structures of the XML documents, due to further neglected forms of structural components.  To overcome these limitations, a new hierarchical approach is proposed, that allows to consider (if necessary) multiple forms of structural components to isolate structurally-homogeneous clusters of XML documents. At each level of the resulting hierarchy, clusters are divided by considering some type of structural components (unaddressed at the preceding levels), that still differentiate the structures of the XML documents. Each cluster in the hierarchy is summarized through a novel technique, that provides a clear and differentiated understanding of its structural properties.","tags":["Clustering","XML/XSL/RDF","Text Mining"],"title":"Hierarchical clustering of XML documents focused on structural components","type":"publication"},{"authors":["Nicola Barbieri","Francesco Bonchi","Giuseppe Manco"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"48c4b02379dd3a6fb64543abbedafebb","permalink":"https://gmanco.github.io/publication/barbieri-2013/","publishdate":"2019-09-07T09:18:44.869871Z","relpermalink":"/publication/barbieri-2013/","section":"publication","summary":"Given a directed social graph and a set of past informa- tion cascades observed over the graph, we study the novel problem of detecting modules of the graph (communities of nodes), that also explain the cascades. Our key observation is that both information propagation and social ties forma- tion in a social network can be explained according to the same latent factor, which ultimately guide a user behavior within the network. Based on this observation, we propose the Community-Cascade Network (CCN) model, a stochas- tic mixture membership generative model that can fit, at the same time, the social graph and the observed set of cas- cades. Our model produces overlapping communities and for each node, its level of authority and passive interest in each community it belongs. For learning the parameters of the CCN model, we devise a Generalized Expectation Maximization procedure. We then apply our model to real-world social networks and in- formation cascades: the results witness the validity of the proposed CCN model, providing useful insights on its signif- icance for analyzing social behavior.","tags":["Social Influence","Topic Models","Community Detection","Generative Models","Social Network Analysis"],"title":"Cascade-based community detection","type":"publication"},{"authors":["Nicola Barbieri","Francesco Bonchi","Giuseppe Manco"],"categories":null,"content":"","date":1354320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1354320000,"objectID":"352df88f3645218d0fc66ae45e522983","permalink":"https://gmanco.github.io/publication/barbieri-2012-a/","publishdate":"2019-09-07T09:18:44.875598Z","relpermalink":"/publication/barbieri-2012-a/","section":"publication","summary":"We study social influence from a topic modeling perspective. We introduce novel topic-aware influence-driven propagation models that experimentally result to be more accurate in describing real-world cascades than the standard propagation models studied in the literature. In particular, we first propose simple topic-aware extensions of the well-known Independent Cascade and Linear Threshold models. Next, we propose a different approach explicitly modeling authoritativeness, influence and relevance under a topic-aware perspective. We devise methods to learn the parameters of the models from a dataset of past propagations. Our experimentation confirms the high accuracy of the proposed models and learning schemes.","tags":["Social Influence","Topic Models","Probabilistic Modeling","Information Diffusion"],"title":"Topic-Aware Social Influence Propagation Models","type":"publication"},{"authors":["Nicola Barbieri","Giuseppe Manco","Riccardo Ortale","Ettore Ritacco"],"categories":null,"content":"","date":1333238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1333238400,"objectID":"02c86828bd713baac70caab874665ec8","permalink":"https://gmanco.github.io/publication/barbieri-2012/","publishdate":"2019-09-07T09:18:44.868885Z","relpermalink":"/publication/barbieri-2012/","section":"publication","summary":"Recent works in Recommender Systems (RS) have investigated the relationships between the prediction accuracy, i.e. the ability of a RS to minimize a cost function (for instance the RMSE measure) in estimating users' preferences, and the accuracy of the recommendation list provided to users. State-of-the-art recommendation algorithms, which focus on the minimization of RMSE, have shown to achieve weak results from the recommendation accuracy perspective, and vice versa. In this work we present a novel Bayesian probabilistic hierarchical approach for users' preference data, which is designed to overcome the limitation of current methodologies and thus to meet both prediction and recommendation accuracy. According to the generative semantics of this technique, each user is modeled as a random mixture over latent factors, which identify users community interests. Each individual user community is then modeled as a mixture of topics, which capture the preferences of the members on a set of items. We provide two different formalization of the basic hierarchical model: BH-Forced focuses on rating prediction, while BH-Free models both the popularity of items and the distribution over item ratings. The combined modeling of item popularity and rating provides a powerful framework for the generation of highly accurate recommendations. An extensive evaluation over two popular benchmark datasets reveals the effectiveness and the quality of the proposed algorithms, showing that BH-Free realizes the most satisfactory compromise between prediction and recommendation accuracy with respect to several state-of-the-art competitors.   Read More: https://epubs.siam.org/doi/10.1137/1.9781611972825.89","tags":["Recommender Systems","Collaborative Filtering","Probabilistic Modeling"],"title":"Balancing Prediction and Recommendation Accuracy: Hierarchical Latent Factors for Preference Data","type":"publication"},{"authors":["Nicola Barbieri","Antonio Bevacqua","Marco Carnuccio","Giuseppe Manco","Ettore Ritacco"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"23a1e0d189346e7b6b03ac464b38cc00","permalink":"https://gmanco.github.io/publication/barbieri-bcmr-12/","publishdate":"2019-09-07T09:18:44.873364Z","relpermalink":"/publication/barbieri-bcmr-12/","section":"publication","summary":"Probabilistic topic models are widely used in different contexts to uncover the hidden structure in large text corpora. One of the main features of these models is that generative process follows a bag-of-words assump- tion, i.e each token is independent from the previous one. We extend the popular Latent Dirichlet Allocation model by exploiting a conditional Markovian assumptions, where the token generation depends on the current topic and on the previous token. The resulting model is capable of accommodating temporal correlations among tokens, which better model user behavior. This is particularly significant in a collaborative filtering context, where the choice of a user can be exploited for recommendation purposes, and hence a more realistic and accurate modeling enables better recommendations. For the mentioned model we present a fast Gibbs Sampling procedure for the parameters estimation. A thorough experimental evaluation over real-word data shows the performance advantages, in terms of recall and precision, of the proposed sequence-modeling approach. ","tags":["Recommender Systems","Collaborative Filtering","Topic Models","Generative Models"],"title":"Probabilistic Sequence Modeling for Recommender Systems","type":"publication"},{"authors":["Gianni Costa","Giuseppe Manco","Riccardo Ortale","Ettore Ritacco"],"categories":null,"content":"","date":1322697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322697600,"objectID":"63e9d905cf8b1c93061702907985db4e","permalink":"https://gmanco.github.io/publication/costa-2011/","publishdate":"2019-09-07T09:18:44.882922Z","relpermalink":"/publication/costa-2011/","section":"publication","summary":"We propose two models for improving the performance of rule-based classification under unbalanced and highly imprecise domains. Both models are probabilistic frameworks aimed to boost the performance of basic rule-based classifiers. The first model implements a global-to-local scheme, where the response of a global rule-based classifier is refined by performing a probabilistic analysis of the coverage of its rules. In particular, the coverage of the individual rules is used to learn local probabilistic models, which ultimately refine the predictions from the corresponding rules of the global classifier. The second model implements a dual local-to-global strategy, in which single classification rules are combined within an exponential probabilistic model in order to boost the overall performance as a side effect of mutual influence. Several variants of the basic ideas are studied, and their performances are thoroughly evaluated and compared with state-of-the-art algorithms on standard benchmark datasets.","tags":["Rule Learning","Pattern Discovery","Supervised Learning\"","Probabilistic Modeling"],"title":"From global to local and viceversa: uses of associative rule learning for classification in imprecise environments","type":"publication"},{"authors":["Nicola Barbieri","Giuseppe Manco","Ettore Ritacco"],"categories":null,"content":"","date":1301616000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1301616000,"objectID":"c27195e2c4c989ce357df8bf07fa4379","permalink":"https://gmanco.github.io/publication/barbieri-2011-a/","publishdate":"2019-09-07T09:18:44.867854Z","relpermalink":"/publication/barbieri-2011-a/","section":"publication","summary":"This paper presents a hierarchical probabilistic approach to collaborative filtering which allows the discovery and analysis of both global patterns (i.e., tendency of some products of being ‘universally appreciated’) and local patterns (tendency of users within a community to express a common preference on the same group of items). We reformulate the collaborative filtering approach as a clustering problem in a high-dimensional setting, and propose a probabilistic approach to model the data. The core of our approach is a co-clustering strategy, arranged in a hierarchical fashion: first, user communities are discovered, and then the information provided by each user community is used to discover topics, grouping items into categories. The resulting probabilistic framework can be used for detecting interesting relationships between users and items within user communities. The experimental evaluation shows that the proposed model achieves a competitive prediction accuracy with respect to the state-of-art collaborative filtering approaches.","tags":["Recommender Systems","Collaborative Filtering","Probabilistic Modeling"],"title":"A Probabilistic Hierarchical Approach for Pattern Discovery in Collaborative Filtering Data","type":"publication"},{"authors":["Nicola Barbieri","Giuseppe Manco"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"248733af9796133cd02548f4b7819a54","permalink":"https://gmanco.github.io/publication/barbieri-2011/","publishdate":"2019-09-07T09:18:44.865034Z","relpermalink":"/publication/barbieri-2011/","section":"publication","summary":"In this work we perform an analysis of probabilistic approaches to recommendation upon a different validation perspective, which focuses on accuracy metrics such as recall and precision of the recommendation list. Traditionally, state-of-art approches to recommendations consider the recommendation process from a “missing value prediction” perspective. This approach simplifies the model validation phase that is based on the minimization of standard error metrics such as RMSE. However, recent studies have pointed several limitations of this approach, showing that a lower RMSE does not necessarily imply improvements in terms of specific recommendations. We demonstrate that the underlying probabilistic framework offers several advantages over traditional methods, in terms of flexibility in the generation of the recommendation list and consequently in the accuracy of recommendation.","tags":["Recommender Systems","Collaborative Filtering","Probabilistic Modeling","Matrix Factorization","Topic Models"],"title":"An Analysis of Probabilistic Methods for Top-N Recommendation in Collaborative Filtering","type":"publication"},{"authors":["Nicola Barbieri","Gianni Costa","Giuseppe Manco","Riccardo Ortale"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"0d4d5c709cefd29dee1d63854eac7eff","permalink":"https://gmanco.github.io/publication/barbieri-2011-b/","publishdate":"2019-09-07T09:18:44.872528Z","relpermalink":"/publication/barbieri-2011-b/","section":"publication","summary":"We propose a bayesian probabilistic model for explicit preference data. The model introduces a generative process, which takes into account both item selection and rating emission to gather into communities those users who experience the same items and tend to adopt the same rating pattern. Each user is modeled as a random mixture of topics, where each topic is characterized by a distribution modeling the popularity of items within the respective user-community and by a distribution over preference values for those items. The proposed model can be associated with a novel item-relevance ranking criterion, which is based both on item popularity and user's preferences. We show that the proposed model, equipped with the new ranking criterion, outperforms state-of-art approaches in terms of accuracy of the recommendation list provided to users on standard benchmark datasets.","tags":["Recommender Systems","Collaborative Filtering","Probabilistic Modeling"],"title":"Modeling item selection and relevance for accurate recommendations","type":"publication"},{"authors":["Gianni Costa","Giuseppe Manco","Riccardo Ortale"],"categories":null,"content":"","date":1254355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1254355200,"objectID":"0fc74d0452b89a832b826adc2f1daa9e","permalink":"https://gmanco.github.io/publication/costa-2009/","publishdate":"2019-09-07T09:18:44.878072Z","relpermalink":"/publication/costa-2009/","section":"publication","summary":"We propose an incremental technique for discovering duplicates in large databases of textual sequences, i.e., syntactically different tuples, that refer to the same real-world entity. The problem is approached from a clustering perspective: given a set of tuples, the objective is to partition them into groups of duplicate tuples. Each newly arrived tuple is assigned to an appropriate cluster via nearest-neighbor classification. This is achieved by means of a suitable hash-based index, that maps any tuple to a set of indexing keys and assigns tuples with high syntactic similarity to the same buckets. Hence, the neighbors of a query tuple can be efficiently identified by simply retrieving those tuples that appear in the same buckets associated to the query tuple itself, without completely scanning the original database. Two alternative schemes for computing indexing keys are discussed and compared. An extensive experimental evaluation on both synthetic and real data shows the effectiveness of our approach.","tags":["Clustering","Indexing","Hashing","similarity measures","Entity resolution","Deduplication"],"title":"An incremental clustering scheme for data de-duplication","type":"publication"},{"authors":["E. Cesario","G. Manco","R. Ortale"],"categories":null,"content":"","date":1196467200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1196467200,"objectID":"166983565a1c198614c9239ad956de13","permalink":"https://gmanco.github.io/publication/cesario-2007-a/","publishdate":"2019-09-07T09:18:44.889808Z","relpermalink":"/publication/cesario-2007-a/","section":"publication","summary":"A parameter-free, fully-automatic approach to clustering high-dimensional categorical data is proposed. The technique is based on a two-phase iterative procedure, which attempts to improve the overall quality of the whole partition. In the first phase, cluster assignments are given, and a new cluster is added to the partition by identifying and splitting a low-quality cluster. In the second phase, the number of clusters is fixed, and an attempt to optimize cluster assignments is done. On the basis of such features, the algorithm attempts to improve the overall quality of the whole partition and finds clusters in the data, whose number is naturally established on the basis of the inherent features of the underlying data set rather than being previously specified. Furthermore, the approach is parametric to the notion of cluster quality: Here, a cluster is defined as a set of tuples exhibiting a sort of homogeneity. We show how a suitable notion of cluster homogeneity can be defined in the context of high-dimensional categorical data, from which an effective instance of the proposed clustering scheme immediately follows. Experiments on both synthetic and real data prove that the devised algorithm scales linearly and achieves nearly optimal results in terms of compactness and separation.","tags":["Clustering","Transactional Data","Information Retrieval"],"title":"Top-Down Parameter-Free Clustering of High-Dimensional Categorical Data","type":"publication"},{"authors":["Gianluigi Greco","Antonella Guzzo","Giuseppe Manco","Domenico Saccà"],"categories":null,"content":"","date":1183248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1183248000,"objectID":"30b6d7bbc14667bf5496618a7d56b3db","permalink":"https://gmanco.github.io/publication/greco-2007/","publishdate":"2019-09-07T09:18:44.887112Z","relpermalink":"/publication/greco-2007/","section":"publication","summary":"General patterns of execution that have been frequently scheduled by a workflow management system provide the administrator with previously unknown, and potentially useful information, e.g., about the existence of unexpected causalities between subprocesses of a given workflow. This paper investigates the problem of mining unconnected patterns on the basis of some execution traces, i.e., of detecting sets of activities exhibiting no explicit dependency relationships that are frequently executed together. The problem is faced in the paper by proposing and analyzing two algorithms. One algorithm takes into account information about the structure of the control-flow graph only, while the other is a smart refinement where the knowledge of the frequencies of edges and activities in the traces at hand is also accounted for, by means of a sophisticated graphical analysis. Both algorithms have been implemented and integrated into a system prototype, which may profitably support the enactment phase of the workflow. The correctness of the two algorithms is formally proven, and several experiments are reported to evidence the ability of the graphical analysis to significantly improve the performances, by dramatically pruning the search space of candidate patterns.","tags":["Pattern discovery","Graph Mining","Workflow Mining"],"title":"Mining unconnected patterns in workflows","type":"publication"},{"authors":["Eugenio Cesario","Francesco Folino","Antonio Locane","Giuseppe Manco","Riccardo Ortale"],"categories":null,"content":"","date":1180656000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1180656000,"objectID":"9eb57127a252da29104ffb80a923daca","permalink":"https://gmanco.github.io/publication/cesario-2007/","publishdate":"2019-09-07T09:18:44.879152Z","relpermalink":"/publication/cesario-2007/","section":"publication","summary":"A novel approach for reconciling tuples stored as free text into an existing attribute schema is proposed. The basic idea is to subject the available text to progressive classification, i.e., a multi-stage classification scheme where, at each intermediate stage, a classifier is learnt that analyzes the textual fragments not reconciled at the end of the previous steps. Classification is accomplished by an ad hoc exploitation of traditional association mining algorithms, and is supported by a data transformation scheme which takes advantage of domain-specific dictionaries/ontologies. A key feature is the capability of progressively enriching the available ontology with the results of the previous stages of classification, thus significantly improving the overall classification accuracy. An extensive experimental evaluation shows the effectiveness of our approach.","tags":["Supervised Learning","Schema Reconciliation","Text Segmentation"],"title":"Boosting text segmentation via progressive classification","type":"publication"},{"authors":["Sergio Flesca","Giuseppe Manco","Elio Masciari","Luigi Pontieri","Andrea Pugliese"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"69865ec9aeae0da1fc331f35f6c9da57","permalink":"https://gmanco.github.io/publication/flesca-2007/","publishdate":"2019-09-07T09:18:44.880158Z","relpermalink":"/publication/flesca-2007/","section":"publication","summary":"In this paper, we propose a classification technique for Web pages, based on the detection of structural similarities among semistructured documents, and devise an architecture exploiting such technique for the purpose of information extraction. The proposal significantly differs from standard methods based on graph-matching algorithms, and is based on the idea of representing the structure of a document as a time series in which each occurrence of a tag corresponds to an impulse. The degree of similarity between documents is then stated by analyzing the frequencies of the corresponding Fourier transform. Experiments on real data show the effectiveness of the proposed technique.","tags":["Semistructured data","Wrapping","WWW tools"],"title":"Exploiting structural similarity for effective Web information extraction","type":"publication"},{"authors":["Giuseppe Manco","Elio Masciari","Andrea Tagarelli"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"127b0abc42e265e1a8a3b06ba250b1d7","permalink":"https://gmanco.github.io/publication/manco-2007/","publishdate":"2019-09-07T09:18:44.885957Z","relpermalink":"/publication/manco-2007/","section":"publication","summary":"The continuous exchange of information by means of the popular email service has raised the problem of managing the huge amounts of messages received from users in an effective and efficient way. We deal with the problem of email classification by conceiving suitable strategies for: (1) organizing messages into homogeneous groups, (2) redirecting further incoming messages according to an initial organization, and (3) building reliable descriptions of the message groups discovered. We propose a unified framework for handling and classifying email messages. In our framework, messages sharing similar features are clustered in a folder organization. Clustering and pattern discovery techniques for mining structured and unstructured information from email messages are the basis of an overall process of folder creation/maintenance and email redirection. Pattern discovery is also exploited for generating suitable cluster descriptions that play a leading role in cluster updating. Experimental evaluation performed on several personal mailboxes shows the effectiveness of our approach.","tags":["Email classification","Text Mining","Clustering","Pattern discovery"],"title":"Mining categories for emails via clustering and pattern discovery","type":"publication"},{"authors":["G. Greco","A. Guzzo","G. Manco","D. Sacca"],"categories":null,"content":"","date":1112313600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1112313600,"objectID":"d41407ea9acba0e933cddaad58272d84","permalink":"https://gmanco.github.io/publication/greco-2005/","publishdate":"2019-09-07T09:18:44.884838Z","relpermalink":"/publication/greco-2005/","section":"publication","summary":"Today's workflow management systems represent a key technological infrastructure for advanced applications that is attracting a growing body of research, mainly focused in developing tools for workflow management, that allow users both to specify the \"static\" aspects, like preconditions, precedences among activities, and rules for exception handling, and to control its execution by scheduling the activities on the available resources. This paper deals with an aspect of workflows which has so far not received much attention even though it is crucial for the forthcoming scenarios of large scale applications on the Web: providing facilities for the human system administrator for identifying the choices performed more frequently in the past that had lead to a desired final configuration. In this context, we formalize the problem of discovering the most frequent patterns of executions, i.e., the workflow substructures that have been scheduled more frequently by the system. We attacked the problem by developing two data mining algorithms on the basis of an intuitive and original graph formalization of a workflow schema and its occurrences. The model is used both to prove some intractability results that strongly motivate the use of data mining techniques and to derive interesting structural properties for reducing the search space for frequent patterns. Indeed, the experiments we have carried out show that our algorithms outperform standard data mining algorithms adapted to discover frequent patterns of workflow executions.","tags":["Pattern discovery","Graph Mining","Workflow Mining"],"title":"Mining and reasoning on workflows","type":"publication"},{"authors":["S. Flesca","G. Manco","E. Masciari","L. Pontieri","A. Pugliese"],"categories":null,"content":"","date":1107216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1107216000,"objectID":"90e8a8f82be260b63a60ab570b13e4cd","permalink":"https://gmanco.github.io/publication/flesca-2005/","publishdate":"2019-09-07T09:18:44.881471Z","relpermalink":"/publication/flesca-2005/","section":"publication","summary":"Because of the widespread diffusion of semistructured data in XML format, much research effort is currently devoted to support the storage and retrieval of large collections of such documents. XML documents can be compared as to their structural similarity, in order to group them into clusters so that different storage, retrieval, and processing techniques can be effectively exploited. In this scenario, an efficient and effective similarity function is the key of a successful data management process. We present an approach for detecting structural similarity between XML documents which significantly differs from standard methods based on graph-matching algorithms, and allows a significant reduction of the required computation costs. Our proposal roughly consists of linearizing the structure of each XML document, by representing it as a numerical sequence and, then, comparing such sequences through the analysis of their frequencies. First, some basic strategies for encoding a document are proposed, which can focus on diverse structural facets. Moreover, the theory of discrete Fourier transform is exploited to effectively and efficiently compare the encoded documents (i.e., signals) in the domain of frequencies. Experimental results reveal the effectiveness of the approach, also in comparison with standard methods.","tags":["Web Mining","Data Mining","XML/XSL/RDF","Text Mining","Similarity Measures"],"title":"Fast detection of XML structural similarity","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f1d044c0738ab9f19347f15c290a71a1","permalink":"https://gmanco.github.io/research/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/research/","section":"","summary":"","tags":null,"title":"","type":"page"}]