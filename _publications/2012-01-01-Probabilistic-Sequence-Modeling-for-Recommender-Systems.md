---
title: "Probabilistic Sequence Modeling for Recommender Systems"
collection: publications
permalink: /publication/2012-01-01-Probabilistic-Sequence-Modeling-for-Recommender-Systems
excerpt: 'Probabilistic topic models are widely used in different contexts to uncover the hidden structure in large text corpora. One of the main features of these models is that generative process follows a bag-of-words assump- tion, i.e each token is independent from the previous one. We extend the popular Latent Dirichlet Allocation model by exploiting a conditional Markovian assumptions, where the token generation depends on the cur- rent topic and on the previous token. The resulting model is capable of accommodating temporal correlations among tokens, which better model user behavior. This is particularly significant in a collaborative filtering context, where the choice of a user can be exploited for recommendation purposes, and hence a more re- alistic and accurate modeling enables better recommendations. For the mentioned model we present a fast Gibbs Sampling procedure for the parameters estimation. A thorough experimental evaluation over real-word data shows the performance advantages, in terms of recall and precision, of the proposed sequence-modeling approach.'
date: 2012-01-01
venue: 'In the proceedings of KDIR 2012 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Barcelona, Spain, 4 - 7 October, 2012'
paperurl: 'https://www.dropbox.com/s/qgljal7gezvt27q/kdir2012_final.pdf?dl=0'
citation: ' Nicola Barbieri,  Antonio Bevacqua,  Marco Carnuccio,  Giuseppe Manco,  Ettore Ritacco, &quot;Probabilistic Sequence Modeling for Recommender Systems.&quot; In the proceedings of KDIR 2012 - Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Barcelona, Spain, 4 - 7 October, 2012, 2012.'
---
Probabilistic topic models are widely used in different contexts to uncover the hidden structure in large text corpora. One of the main features of these models is that generative process follows a bag-of-words assump- tion, i.e each token is independent from the previous one. We extend the popular Latent Dirichlet Allocation model by exploiting a conditional Markovian assumptions, where the token generation depends on the cur- rent topic and on the previous token. The resulting model is capable of accommodating temporal correlations among tokens, which better model user behavior. This is particularly significant in a collaborative filtering context, where the choice of a user can be exploited for recommendation purposes, and hence a more re- alistic and accurate modeling enables better recommendations. For the mentioned model we present a fast Gibbs Sampling procedure for the parameters estimation. A thorough experimental evaluation over real-word data shows the performance advantages, in terms of recall and precision, of the proposed sequence-modeling approach.

[Access paper here](https://www.dropbox.com/s/qgljal7gezvt27q/kdir2012_final.pdf?dl=0){:target="_blank"}
