<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Courses | Giuseppe Manco</title>
    <link>https://gmanco.github.io/courses/</link>
      <atom:link href="https://gmanco.github.io/courses/index.xml" rel="self" type="application/rss+xml" />
    <description>Courses</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2021 Giuseppe Manco</copyright><lastBuildDate>Tue, 12 May 2020 00:00:00 +0100</lastBuildDate>
    <image>
      <url>https://gmanco.github.io/img/manco.jpg</url>
      <title>Courses</title>
      <link>https://gmanco.github.io/courses/</link>
    </image>
    
    <item>
      <title>Panoramica</title>
      <link>https://gmanco.github.io/courses/computervision/</link>
      <pubDate>Mon, 01 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://gmanco.github.io/courses/computervision/</guid>
      <description>

&lt;h2 id=&#34;annunci&#34;&gt;Annunci&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;[12/04/2021]&lt;/strong&gt; I risultati del primo esonero  sono disponibili al seguente &lt;a href=&#34;https://gmanco.github.io/courses/computervision/esoneri/esonero1/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[01/03/2021]&lt;/strong&gt; Questo è il sito web dell&amp;rsquo;edizione 2020-2021 del corso. L&amp;rsquo;edizione precedente è disponibile al sequente &lt;a href=&#34;https://gmanco.github.io/courses/computervision/2020/&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[03/03/2021]&lt;/strong&gt; Si avvisano gli studenti che il corso di Analisi di Immagini e Video – Corso di Laurea Magistrale in Ingegneria Informatica verrà inizialmente erogato in modalità streaming, utilizzando l’applicativo TEAMS, a partire dal giorno 02/03/2019, alle ore 11:30. La richiesta di iscrizione al corso può essere effettuata cliccando sul seguente &lt;a href=&#34;https://teams.microsoft.com/l/team/19%3a85cc03830d8145e9b23ab2b9f21641f0%40thread.tacv2/conversations?groupId=8bbaa92e-68d3-4c10-887f-157c5a2392ab&amp;amp;tenantId=7519d0cd-2106-47d9-adcb-320023abff57&#34; target=&#34;_blank&#34;&gt;link&lt;/a&gt;. Gli studenti già pratici dell’utilizzo di TEAMS e che abbiano già scaricato l’APP, possono iscriversi direttamente al corso (senza approvazione del docente) utilizzando il codice: &lt;strong&gt;czo3mqk&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;breve-descrizione-del-corso&#34;&gt;Breve descrizione del corso&lt;/h2&gt;

&lt;p&gt;Il corso è finalizzato ad acquisire e sperimentare le tecniche di base per l’analisi di immagini e video. Verranno illustrati i concetti fondamentali per l’analisi delle immagini e verranno illustrate le principali tecniche di object detection, object tracking e action detection. Durante il corso saranno presentati modelli di reti neurali CNN e RNN, tecniche di transfer learning, Residual and Attention network ed una introduzione ai modelli generativi e alle Adversarial networks. Gli esempi applicativi faranno uso del linguaggio Python e dei framework di Deep Learning Pytorch/Tensorflow.&lt;/p&gt;

&lt;p&gt;Competenze specifiche:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;comprensione dei concetti legati all’image e al video processing&lt;/li&gt;
&lt;li&gt;conoscenza degli aspetti caratterizzanti di machine learning e deep learning&lt;/li&gt;
&lt;li&gt;comprensione delle principali tecniche per l’analisi di immagini e video&lt;/li&gt;
&lt;li&gt;abilità di utilizzare algoritmi di image analysis per la risoluzione di problemi specifici&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;docenti&#34;&gt;Docenti&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Giuseppe Manco. Ricevimento: mercoledì’ 14:30-16:30.&lt;/li&gt;
&lt;li&gt;Francesco Pisani. Rivevimento lunedì 15-17.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;programma&#34;&gt;Programma&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Introduzione alla computer vision&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Concetti fondamentali su Image processing e analysis: Image Basics, Python per Image Processing, Manipolazione di immagini.&lt;/li&gt;
&lt;li&gt;Trasformazioni: Normalizzazione, filtri, Edge detection, morfologia, thresholding e segmentazione.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Classificazione di immagini e video&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Introduzione alla classificazione: applicazioni; approcci classici; scikit-Learn per la classificazione; limitazioni.&lt;/li&gt;
&lt;li&gt;Deep Learning: Review su Neural Networks per l&amp;rsquo;analisi di immagini e video. Convolutional Neural Networks. Reti ricorrenti. Gestione dell&amp;rsquo;overfitting.&lt;/li&gt;
&lt;li&gt;Concetti avanzati. Principali architetture di rete e loro caratteristiche: VGG, AlexNet, Inception and Residual Networks, Attention Networks. Transfer Learning.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concetti avanzati&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Object Detection: Sliding windows, boundary boxes e anchors. Region Proposal Networks. Yolo e Darknet. Applicazioni.&lt;/li&gt;
&lt;li&gt;Object tracking e action recognition. Optical flow; Single/multiple objects tracking; Action classification and localization.&lt;/li&gt;
&lt;li&gt;Image segmentation e synthesis. UNet. Neural style transfer.&lt;/li&gt;
&lt;li&gt;Modelli Generativi: Probabilistic Modeling, Autoencoders. Generative Adversarial Networks. Applicazioni: Colorization, Reconstruction, Super-Resolution, Synthesis, Text-to-image.&lt;/li&gt;
&lt;li&gt;Adversarial Machine Learning. Principali attacchi e contromisure. Adversarial-free deep networks.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;materiale-didattico&#34;&gt;Materiale didattico&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Lucidi delle lezioni&lt;/li&gt;
&lt;li&gt;Notebooks e lucidi delle esercitazioni&lt;/li&gt;
&lt;li&gt;Libri di consultazione:

&lt;ul&gt;
&lt;li&gt;E.R. Davies, Computer Vision: Principles, Algorithms, Applications, Learning. Fifth edition. Elsevier/Academic Press, 2018 &lt;strong&gt;[Davies18]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Jan Erik Solem, Programming Computer Vision with Python. O&amp;rsquo;Reilly Media, 2012. &lt;strong&gt;[Solem12]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Mohamed Elgendy, &lt;a href=&#34;https://www.manning.com/books/deep-learning-for-vision-systems&#34; target=&#34;_blank&#34;&gt;Deep Learning for Vision Systems&lt;/a&gt;. Manning, 2020. &lt;strong&gt;[Elg20]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Rafael C. Gonzalez, Richard E. Woods, Digital image processing. 4th edition. Pearson, 2018. &lt;strong&gt;[Gon18]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Richard Szeliski, Computer Vision: Algorithms and Applications. Springer, 2011. &lt;strong&gt;[Sze11]&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Jason M.Kinser, Image operators: image processing in Python. CRC Press, 2019. &lt;strong&gt;[Kin19]&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sillabo-delle-lezioni&#34;&gt;Sillabo delle lezioni&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Lezione&lt;/th&gt;
&lt;th&gt;Argomenti&lt;/th&gt;
&lt;th&gt;Materiale didattico&lt;/th&gt;
&lt;th&gt;Data&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Introduzione al corso&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture1/&#34; target=&#34;_blank&#34;&gt;Slides&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;02/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Python and image processing&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture_lab1/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;04/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Concetti fondamentali su image processing e analysis&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture2/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;09/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;Filtri&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture3/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;11/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Laboratorio: image processing in Python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture_lab2/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;16/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Filtraggio Spaziale e sulle frequenze. Edge Detection&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture4/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;18/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;Edges, lines, shapes&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture5/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;23/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;Laboratorio: Filtri, edge detection&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture_lab3/&#34; target=&#34;_blank&#34;&gt;Slides, notebook&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;25/03/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;Introduzione alla Classification. Features&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture6/&#34; target=&#34;_blank&#34;&gt;Slides, notebooks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;30/03/2021, 13/04/2021, 15/04/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;Reti Neurali. Convoluzione&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture7/&#34; target=&#34;_blank&#34;&gt;Slides, notebooks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;20/04/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;11&lt;/td&gt;
&lt;td&gt;Convoluzione. Laboratorio: SIFT, Introduzione a Pytorch&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture_lab4/&#34; target=&#34;_blank&#34;&gt;Slides, notebooks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;22/04/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;12&lt;/td&gt;
&lt;td&gt;Architetture convoluzionali&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture_lab5/&#34; target=&#34;_blank&#34;&gt;Slides, notebooks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;27/04/2021&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;td&gt;Object Detection&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://gmanco.github.io/courses/computervision/lecture8/&#34; target=&#34;_blank&#34;&gt;Slides, notebooks&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;29/04/2021, 04/05/2021&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Segmentation</title>
      <link>https://gmanco.github.io/courses/lecture8/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0100</pubDate>
      <guid>https://gmanco.github.io/courses/lecture8/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Segmentation.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Approcci classici. Conditional Random Fields. &lt;a href=&#34;../pdf/9a.Segmentation_part1.pdf&#34;&gt;slides&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Approcci Neurali. Semantic Segmentation. Instance Segmentation. &lt;a href=&#34;../pdf/9b.Segmentation_part2.pdf&#34;&gt;slides&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gmanco/cv_notebooks/blob/master/9.Segmentation.ipynb&#34; target=&#34;_blank&#34;&gt;Notebook&lt;/a&gt; di accompagnamento.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;riferimenti-bibliografici&#34;&gt;Riferimenti bibliografici&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;[Sze11]&lt;/strong&gt;, Ch. 5&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Davies18]&lt;/strong&gt;, Ch.11&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;[Gon18]&lt;/strong&gt;, Ch.10&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;link-utili&#34;&gt;Link utili&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf&#34; target=&#34;_blank&#34;&gt;An Introduction to Conditional Random Fields&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.nowozin.net/sebastian/papers/nowozin2011structured-tutorial.pdf&#34; target=&#34;_blank&#34;&gt;Structured Learning and Prediction in Computer Vision&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.csd.uwo.ca/~yboykov/Papers/pami04.pdf&#34; target=&#34;_blank&#34;&gt;An experimental Comparison of Min-cut/Max Flow algorithms for Energy Minimization in Vision&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1210.5644.pdf&#34; target=&#34;_blank&#34;&gt;Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials&lt;/a&gt; (with &lt;a href=&#34;http://vladlen.info/papers/densecrf-supplementary.pdf&#34; target=&#34;_blank&#34;&gt;Supplemental Material&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/conditional-random-fields-explained-e5b8256da776&#34; target=&#34;_blank&#34;&gt;Conditional Random Fields explained&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/&#34; target=&#34;_blank&#34;&gt;Introduction to Conditional Random Fields&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.topbots.com/semantic-segmentation-guide/&#34; target=&#34;_blank&#34;&gt;A simple guide to semantic Segmentation&lt;/a&gt; and &lt;a href=&#34;https://heartbeat.fritz.ai/a-2019-guide-to-semantic-segmentation-ca8242f5a7fc&#34; target=&#34;_blank&#34;&gt;A 2019 guide to semantic segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1605.06211&#34; target=&#34;_blank&#34;&gt;Fully Convolutional Networks for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://towardsdatascience.com/review-fcn-semantic-segmentation-eb8c9b50d2d1&#34; target=&#34;_blank&#34;&gt;Review - FCN&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0&#34; target=&#34;_blank&#34;&gt;Upsampling with Transposed Convolution&lt;/a&gt;; &lt;a href=&#34;https://towardsdatascience.com/transposed-convolution-demystified-84ca81b4baba&#34; target=&#34;_blank&#34;&gt;Transposed Convolution demystified&lt;/a&gt;; &lt;a href=&#34;https://medium.com/apache-mxnet/transposed-convolutions-explained-with-ms-excel-52d13030c7e8&#34; target=&#34;_blank&#34;&gt;Transposed convolutions explained with Excel&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://distill.pub/2016/deconv-checkerboard/&#34; target=&#34;_blank&#34;&gt;Deconvolution and checkerboard artifacts&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://cvlab.postech.ac.kr/research/deconvnet/&#34; target=&#34;_blank&#34;&gt;Learning Deconvolution Network for Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/1511.00561&#34; target=&#34;_blank&#34;&gt;SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation&lt;/a&gt;]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1505.04597.pdf&#34; target=&#34;_blank&#34;&gt;U-Net: Convolutional Networks for Biomedical Image Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.09326&#34; target=&#34;_blank&#34;&gt;The One Hundred Layers Tiramisu&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1612.01105.pdf&#34; target=&#34;_blank&#34;&gt;Pyramid scene parsing Networks&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1606.00915.pdf&#34; target=&#34;_blank&#34;&gt;DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1511.07122&#34; target=&#34;_blank&#34;&gt;Multiscale Context aggregation by dilated convolutions&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1706.05587.pdf&#34; target=&#34;_blank&#34;&gt;Rethinking Atrous Convolution for Semantic Image Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Review: &lt;a href=&#34;https://towardsdatascience.com/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d&#34; target=&#34;_blank&#34;&gt;DeepLabv2&lt;/a&gt; e &lt;a href=&#34;https://towardsdatascience.com/review-deeplabv3-atrous-convolution-semantic-segmentation-6d818bfd1d74&#34; target=&#34;_blank&#34;&gt;DeepLabv3&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://openreview.net/pdf?id=S1uHiFyyg&#34; target=&#34;_blank&#34;&gt;Speeding up Semantic segmentation for autonomous driving&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1606.02147.pdf&#34; target=&#34;_blank&#34;&gt;ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;ICNet for Real-Time Semantic Segmentation on High-Resolution Images&#34; target=&#34;_blank&#34;&gt;ICNet for Real-Time Semantic Segmentation on High-Resolution Images&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1902.04502&#34; target=&#34;_blank&#34;&gt;Fast-SCNN: Fast Semantic Segmentation Network&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://openaccess.thecvf.com/content_CVPR_2019/html/Li_DFANet_Deep_Feature_Aggregation_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.html&#34; target=&#34;_blank&#34;&gt;DFANet: Deep Feature Aggregation for Real-Time Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.06870&#34; target=&#34;_blank&#34;&gt;Mask R-CNN&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272&#34; target=&#34;_blank&#34;&gt;Image Segmentation with Mask R-CNN&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1611.07709.pdf&#34; target=&#34;_blank&#34;&gt;Fully Convolutional Instance-aware Semantic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1904.02689.pdf&#34; target=&#34;_blank&#34;&gt;YOLACT&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/abs/1912.06218&#34; target=&#34;_blank&#34;&gt;YOLOACT++&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1801.00868.pdf&#34; target=&#34;_blank&#34;&gt;Pantropic Segmentation&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
